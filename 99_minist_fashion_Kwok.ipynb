{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print( tf.__version__ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FASHION data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Label   Class\n",
    "0       T-shirt/top\n",
    "1       Trouser\n",
    "2       Pullover\n",
    "3       Dress\n",
    "4       Coat\n",
    "5       Sandal\n",
    "6       Shirt\n",
    "7       Sneaker\n",
    "8       Bag\n",
    "9       Ankle boot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loan in Fashion Data\n",
    "mnist = tf.keras.datasets.fashion_mnist # 28x28 Fashion Image Data\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "              'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot' ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NUMBER data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in Data\n",
    "# mnist = tf.keras.datasets.mnist # 28x28 Handwritten Digits 0-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize the Data\n",
    "#x_train = tf.keras.utils.normalize( x_train, axis=1 )\n",
    "#x_test = tf.keras.utils.normalize( x_test, axis=1 )\n",
    "\n",
    "x_train = x_train / 255 \n",
    "x_test = x_test / 255 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(60000, 28, 28)\n",
      "<class 'numpy.ndarray'>\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print( type( x_train ) )\n",
    "print( x_train.shape )\n",
    "\n",
    "print( type( y_train ) )\n",
    "print( y_train.shape )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape =  (28, 28)\n",
      "TOTAL SIZE =  784\n"
     ]
    }
   ],
   "source": [
    "INPUT_SHAPE = x_train[0].shape\n",
    "print(\"Shape = \", INPUT_SHAPE )\n",
    "\n",
    "TOTAL_SIZE = INPUT_SHAPE[0] * INPUT_SHAPE[1]\n",
    "print(\"TOTAL SIZE = \", TOTAL_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRandomIndex( DATA ) :\n",
    "    return random.randint(0, DATA.shape[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "who= 5602\n",
      "7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x29e6bd990>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "who=0\n",
    "who=getRandomIndex( x_train )\n",
    "\n",
    "print(\"who=\", who)\n",
    "\n",
    "print( y_train[who])\n",
    "#print( x_train[who])\n",
    "plt.imshow(x_train[who], plt.cm.binary) \n",
    "#plt.imshow(x_train[who] ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOLVE USING RANDOM FORESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "new_x_train = []\n",
    "for i in x_train :\n",
    "    new_x_train.append( i.flatten() )\n",
    "new_x_train = np.array( new_x_train )\n",
    "\n",
    "new_x_test = []\n",
    "for i in x_test :\n",
    "    new_x_test.append( i.flatten() )\n",
    "new_x_test = np.array( new_x_test )\n",
    "\n",
    "print( x_train.shape )\n",
    "print( new_x_train.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This might take a while ... maybe 15+ minutes ...depends on your computer.\n",
      "Execution Time In Seconds =  885.0\n",
      "Execution Time In Minutes =  14.8\n"
     ]
    }
   ],
   "source": [
    "print(\"This might take a while ... maybe 15+ minutes ...depends on your computer.\")\n",
    "start_time = time.time()\n",
    "\n",
    "theTrees = int( 2*TOTAL_SIZE )\n",
    "\n",
    "clf = RandomForestClassifier( n_estimators = theTrees )\n",
    "clf.fit( new_x_train, y_train )\n",
    "\n",
    "Time_In_Seconds = round( time.time()-start_time, 0 )\n",
    "Time_In_Minutes = round( Time_In_Seconds / 60, 1 )\n",
    "print(\"Execution Time In Seconds = \", Time_In_Seconds )\n",
    "print(\"Execution Time In Minutes = \", Time_In_Minutes )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "train accuracy 1.0\n",
      "9\n",
      "test accuracy 0.8784\n"
     ]
    }
   ],
   "source": [
    "pred_train = clf.predict( new_x_train )\n",
    "print( pred_train[0] )\n",
    "RF_acc_train = metrics.accuracy_score(y_train, pred_train )\n",
    "print( \"train accuracy\", RF_acc_train )\n",
    "\n",
    "pred_test = clf.predict( new_x_test )\n",
    "print( pred_test[0] )\n",
    "RF_acc = metrics.accuracy_score(y_test, pred_test )\n",
    "print( \"test accuracy\", RF_acc )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOLVE USING TENSOR FLOW NEURAL NETWORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "theEpochs = 1000\n",
    "\n",
    "theActivation = tf.keras.activations.relu\n",
    "\n",
    "\n",
    "units_01 = int( 2*TOTAL_SIZE )\n",
    "units_02 = units_01\n",
    "\n",
    "DENSE_LAYER_01 = tf.keras.layers.Dense( units=units_01, activation=theActivation )\n",
    "DENSE_LAYER_02 = tf.keras.layers.Dense( units=units_02, activation=theActivation )\n",
    "DENSE_LAYER_XX = tf.keras.layers.Dense(10, activation=tf.nn.softmax )\n",
    "\n",
    "DROPOUT_LAYER = tf.keras.layers.Dropout( 0.2 )\n",
    "\n",
    "\n",
    "theOptimizer = tf.keras.optimizers.Adam()\n",
    "theLossMetric = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "theSplit = 0.2\n",
    "theBatchSize = 32\n",
    "verboseFlag = True\n",
    "\n",
    "theTensorFlowSaveFile = \"TF_Fashion_Model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This might take a while ... maybe 15+ minutes ...depends on your computer.\n",
      "Epoch 1/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.5112 - accuracy: 0.8123 - val_loss: 0.4381 - val_accuracy: 0.8433\n",
      "Epoch 2/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.3978 - accuracy: 0.8537 - val_loss: 0.3868 - val_accuracy: 0.8590\n",
      "Epoch 3/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.3627 - accuracy: 0.8655 - val_loss: 0.3759 - val_accuracy: 0.8583\n",
      "Epoch 4/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.3427 - accuracy: 0.8735 - val_loss: 0.3475 - val_accuracy: 0.8712\n",
      "Epoch 5/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.3212 - accuracy: 0.8795 - val_loss: 0.3915 - val_accuracy: 0.8629\n",
      "Epoch 6/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.3100 - accuracy: 0.8852 - val_loss: 0.3588 - val_accuracy: 0.8739\n",
      "Epoch 7/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.2987 - accuracy: 0.8886 - val_loss: 0.3474 - val_accuracy: 0.8731\n",
      "Epoch 8/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.2883 - accuracy: 0.8914 - val_loss: 0.3262 - val_accuracy: 0.8857\n",
      "Epoch 9/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.2782 - accuracy: 0.8954 - val_loss: 0.3276 - val_accuracy: 0.8897\n",
      "Epoch 10/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.2773 - accuracy: 0.8966 - val_loss: 0.3199 - val_accuracy: 0.8882\n",
      "Epoch 11/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.2700 - accuracy: 0.8995 - val_loss: 0.3203 - val_accuracy: 0.8866\n",
      "Epoch 12/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.2598 - accuracy: 0.9019 - val_loss: 0.3366 - val_accuracy: 0.8861\n",
      "Epoch 13/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.2566 - accuracy: 0.9045 - val_loss: 0.3227 - val_accuracy: 0.8868\n",
      "Epoch 14/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.2527 - accuracy: 0.9042 - val_loss: 0.3255 - val_accuracy: 0.8882\n",
      "Epoch 15/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.2452 - accuracy: 0.9080 - val_loss: 0.3525 - val_accuracy: 0.8853\n",
      "Epoch 16/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.2404 - accuracy: 0.9098 - val_loss: 0.3268 - val_accuracy: 0.8869\n",
      "Epoch 17/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.2368 - accuracy: 0.9116 - val_loss: 0.3336 - val_accuracy: 0.8903\n",
      "Epoch 18/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.2320 - accuracy: 0.9126 - val_loss: 0.3414 - val_accuracy: 0.8903\n",
      "Epoch 19/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.2277 - accuracy: 0.9145 - val_loss: 0.3299 - val_accuracy: 0.8934\n",
      "Epoch 20/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.2237 - accuracy: 0.9172 - val_loss: 0.3477 - val_accuracy: 0.8868\n",
      "Epoch 21/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.2175 - accuracy: 0.9169 - val_loss: 0.3265 - val_accuracy: 0.8929\n",
      "Epoch 22/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.2171 - accuracy: 0.9182 - val_loss: 0.3530 - val_accuracy: 0.8828\n",
      "Epoch 23/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.2105 - accuracy: 0.9208 - val_loss: 0.3336 - val_accuracy: 0.8949\n",
      "Epoch 24/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.2147 - accuracy: 0.9209 - val_loss: 0.3578 - val_accuracy: 0.8885\n",
      "Epoch 25/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.2112 - accuracy: 0.9206 - val_loss: 0.3511 - val_accuracy: 0.8953\n",
      "Epoch 26/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.2077 - accuracy: 0.9224 - val_loss: 0.3451 - val_accuracy: 0.8987\n",
      "Epoch 27/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.2026 - accuracy: 0.9233 - val_loss: 0.3600 - val_accuracy: 0.8988\n",
      "Epoch 28/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.2052 - accuracy: 0.9232 - val_loss: 0.3491 - val_accuracy: 0.8956\n",
      "Epoch 29/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1974 - accuracy: 0.9261 - val_loss: 0.3729 - val_accuracy: 0.8932\n",
      "Epoch 30/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1973 - accuracy: 0.9252 - val_loss: 0.3765 - val_accuracy: 0.8951\n",
      "Epoch 31/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1920 - accuracy: 0.9266 - val_loss: 0.3682 - val_accuracy: 0.8948\n",
      "Epoch 32/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1930 - accuracy: 0.9299 - val_loss: 0.3713 - val_accuracy: 0.8937\n",
      "Epoch 33/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1920 - accuracy: 0.9279 - val_loss: 0.3847 - val_accuracy: 0.8939\n",
      "Epoch 34/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1931 - accuracy: 0.9293 - val_loss: 0.3883 - val_accuracy: 0.8942\n",
      "Epoch 35/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1851 - accuracy: 0.9306 - val_loss: 0.3673 - val_accuracy: 0.8960\n",
      "Epoch 36/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1815 - accuracy: 0.9314 - val_loss: 0.3843 - val_accuracy: 0.8966\n",
      "Epoch 37/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1869 - accuracy: 0.9317 - val_loss: 0.4007 - val_accuracy: 0.8967\n",
      "Epoch 38/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1780 - accuracy: 0.9318 - val_loss: 0.3926 - val_accuracy: 0.9000\n",
      "Epoch 39/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.1801 - accuracy: 0.9329 - val_loss: 0.3921 - val_accuracy: 0.8973\n",
      "Epoch 40/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1731 - accuracy: 0.9350 - val_loss: 0.4081 - val_accuracy: 0.8992\n",
      "Epoch 41/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.1761 - accuracy: 0.9346 - val_loss: 0.4105 - val_accuracy: 0.8963\n",
      "Epoch 42/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1765 - accuracy: 0.9327 - val_loss: 0.4111 - val_accuracy: 0.8963\n",
      "Epoch 43/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1754 - accuracy: 0.9351 - val_loss: 0.3950 - val_accuracy: 0.8990\n",
      "Epoch 44/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1713 - accuracy: 0.9351 - val_loss: 0.4317 - val_accuracy: 0.8958\n",
      "Epoch 45/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1693 - accuracy: 0.9378 - val_loss: 0.4133 - val_accuracy: 0.8969\n",
      "Epoch 46/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1681 - accuracy: 0.9375 - val_loss: 0.4326 - val_accuracy: 0.8955\n",
      "Epoch 47/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1671 - accuracy: 0.9371 - val_loss: 0.3895 - val_accuracy: 0.8991\n",
      "Epoch 48/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1656 - accuracy: 0.9388 - val_loss: 0.4252 - val_accuracy: 0.8946\n",
      "Epoch 49/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1664 - accuracy: 0.9398 - val_loss: 0.4114 - val_accuracy: 0.8984\n",
      "Epoch 50/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1691 - accuracy: 0.9379 - val_loss: 0.4632 - val_accuracy: 0.8957\n",
      "Epoch 51/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1615 - accuracy: 0.9398 - val_loss: 0.4385 - val_accuracy: 0.8886\n",
      "Epoch 52/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1579 - accuracy: 0.9402 - val_loss: 0.4531 - val_accuracy: 0.8967\n",
      "Epoch 53/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1555 - accuracy: 0.9422 - val_loss: 0.4743 - val_accuracy: 0.8961\n",
      "Epoch 54/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1599 - accuracy: 0.9412 - val_loss: 0.4465 - val_accuracy: 0.8983\n",
      "Epoch 55/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1537 - accuracy: 0.9421 - val_loss: 0.4365 - val_accuracy: 0.8945\n",
      "Epoch 56/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1570 - accuracy: 0.9419 - val_loss: 0.4636 - val_accuracy: 0.8971\n",
      "Epoch 57/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1535 - accuracy: 0.9430 - val_loss: 0.4522 - val_accuracy: 0.8972\n",
      "Epoch 58/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1540 - accuracy: 0.9425 - val_loss: 0.4544 - val_accuracy: 0.9012\n",
      "Epoch 59/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1549 - accuracy: 0.9442 - val_loss: 0.4792 - val_accuracy: 0.8967\n",
      "Epoch 60/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1481 - accuracy: 0.9442 - val_loss: 0.4681 - val_accuracy: 0.8985\n",
      "Epoch 61/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1459 - accuracy: 0.9457 - val_loss: 0.4501 - val_accuracy: 0.8979\n",
      "Epoch 62/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1502 - accuracy: 0.9440 - val_loss: 0.4702 - val_accuracy: 0.8962\n",
      "Epoch 63/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1434 - accuracy: 0.9460 - val_loss: 0.5046 - val_accuracy: 0.8918\n",
      "Epoch 64/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1528 - accuracy: 0.9458 - val_loss: 0.4951 - val_accuracy: 0.8944\n",
      "Epoch 65/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1556 - accuracy: 0.9435 - val_loss: 0.4687 - val_accuracy: 0.9023\n",
      "Epoch 66/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1424 - accuracy: 0.9481 - val_loss: 0.4307 - val_accuracy: 0.8989\n",
      "Epoch 67/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1396 - accuracy: 0.9484 - val_loss: 0.4490 - val_accuracy: 0.9016\n",
      "Epoch 68/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1475 - accuracy: 0.9475 - val_loss: 0.4703 - val_accuracy: 0.9003\n",
      "Epoch 69/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1406 - accuracy: 0.9481 - val_loss: 0.4537 - val_accuracy: 0.9031\n",
      "Epoch 70/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1348 - accuracy: 0.9478 - val_loss: 0.4630 - val_accuracy: 0.8952\n",
      "Epoch 71/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1450 - accuracy: 0.9472 - val_loss: 0.4559 - val_accuracy: 0.8973\n",
      "Epoch 72/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1379 - accuracy: 0.9490 - val_loss: 0.5084 - val_accuracy: 0.8961\n",
      "Epoch 73/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1452 - accuracy: 0.9482 - val_loss: 0.4779 - val_accuracy: 0.8966\n",
      "Epoch 74/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1389 - accuracy: 0.9509 - val_loss: 0.4670 - val_accuracy: 0.9007\n",
      "Epoch 75/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1379 - accuracy: 0.9491 - val_loss: 0.4837 - val_accuracy: 0.8997\n",
      "Epoch 76/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1418 - accuracy: 0.9480 - val_loss: 0.5410 - val_accuracy: 0.8959\n",
      "Epoch 77/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1367 - accuracy: 0.9503 - val_loss: 0.4764 - val_accuracy: 0.8979\n",
      "Epoch 78/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1400 - accuracy: 0.9493 - val_loss: 0.5455 - val_accuracy: 0.8963\n",
      "Epoch 79/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1342 - accuracy: 0.9508 - val_loss: 0.5219 - val_accuracy: 0.9018\n",
      "Epoch 80/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1332 - accuracy: 0.9518 - val_loss: 0.5260 - val_accuracy: 0.9011\n",
      "Epoch 81/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1329 - accuracy: 0.9515 - val_loss: 0.5404 - val_accuracy: 0.8994\n",
      "Epoch 82/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1330 - accuracy: 0.9512 - val_loss: 0.5583 - val_accuracy: 0.8974\n",
      "Epoch 83/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1265 - accuracy: 0.9531 - val_loss: 0.5485 - val_accuracy: 0.8992\n",
      "Epoch 84/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1402 - accuracy: 0.9507 - val_loss: 0.5101 - val_accuracy: 0.9008\n",
      "Epoch 85/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1287 - accuracy: 0.9524 - val_loss: 0.5282 - val_accuracy: 0.8966\n",
      "Epoch 86/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1424 - accuracy: 0.9510 - val_loss: 0.5244 - val_accuracy: 0.9007\n",
      "Epoch 87/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1315 - accuracy: 0.9527 - val_loss: 0.5329 - val_accuracy: 0.8993\n",
      "Epoch 88/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1323 - accuracy: 0.9531 - val_loss: 0.5296 - val_accuracy: 0.8953\n",
      "Epoch 89/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1310 - accuracy: 0.9518 - val_loss: 0.5430 - val_accuracy: 0.8994\n",
      "Epoch 90/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1300 - accuracy: 0.9526 - val_loss: 0.5589 - val_accuracy: 0.8967\n",
      "Epoch 91/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1287 - accuracy: 0.9525 - val_loss: 0.5232 - val_accuracy: 0.9002\n",
      "Epoch 92/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1260 - accuracy: 0.9547 - val_loss: 0.5596 - val_accuracy: 0.9000\n",
      "Epoch 93/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1245 - accuracy: 0.9544 - val_loss: 0.5412 - val_accuracy: 0.9022\n",
      "Epoch 94/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1277 - accuracy: 0.9533 - val_loss: 0.5998 - val_accuracy: 0.9003\n",
      "Epoch 95/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1326 - accuracy: 0.9526 - val_loss: 0.5901 - val_accuracy: 0.8987\n",
      "Epoch 96/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1305 - accuracy: 0.9538 - val_loss: 0.5892 - val_accuracy: 0.9003\n",
      "Epoch 97/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1203 - accuracy: 0.9552 - val_loss: 0.5855 - val_accuracy: 0.8980\n",
      "Epoch 98/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1219 - accuracy: 0.9562 - val_loss: 0.6075 - val_accuracy: 0.8970\n",
      "Epoch 99/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1254 - accuracy: 0.9551 - val_loss: 0.6092 - val_accuracy: 0.8996\n",
      "Epoch 100/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1271 - accuracy: 0.9545 - val_loss: 0.5605 - val_accuracy: 0.8992\n",
      "Epoch 101/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1186 - accuracy: 0.9560 - val_loss: 0.6172 - val_accuracy: 0.8959\n",
      "Epoch 102/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1285 - accuracy: 0.9545 - val_loss: 0.5704 - val_accuracy: 0.9033\n",
      "Epoch 103/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1268 - accuracy: 0.9554 - val_loss: 0.5831 - val_accuracy: 0.8957\n",
      "Epoch 104/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1238 - accuracy: 0.9557 - val_loss: 0.6524 - val_accuracy: 0.9011\n",
      "Epoch 105/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1148 - accuracy: 0.9576 - val_loss: 0.6379 - val_accuracy: 0.8980\n",
      "Epoch 106/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1198 - accuracy: 0.9572 - val_loss: 0.5787 - val_accuracy: 0.8996\n",
      "Epoch 107/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1266 - accuracy: 0.9559 - val_loss: 0.5894 - val_accuracy: 0.9013\n",
      "Epoch 108/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1199 - accuracy: 0.9575 - val_loss: 0.6516 - val_accuracy: 0.8974\n",
      "Epoch 109/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1209 - accuracy: 0.9580 - val_loss: 0.6092 - val_accuracy: 0.8953\n",
      "Epoch 110/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1159 - accuracy: 0.9580 - val_loss: 0.6151 - val_accuracy: 0.8991\n",
      "Epoch 111/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1206 - accuracy: 0.9567 - val_loss: 0.5868 - val_accuracy: 0.8932\n",
      "Epoch 112/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1172 - accuracy: 0.9571 - val_loss: 0.6301 - val_accuracy: 0.8967\n",
      "Epoch 113/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1158 - accuracy: 0.9583 - val_loss: 0.6288 - val_accuracy: 0.8990\n",
      "Epoch 114/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1244 - accuracy: 0.9562 - val_loss: 0.5849 - val_accuracy: 0.8993\n",
      "Epoch 115/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1207 - accuracy: 0.9574 - val_loss: 0.6386 - val_accuracy: 0.8963\n",
      "Epoch 116/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1120 - accuracy: 0.9589 - val_loss: 0.6715 - val_accuracy: 0.8973\n",
      "Epoch 117/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1152 - accuracy: 0.9591 - val_loss: 0.6397 - val_accuracy: 0.9004\n",
      "Epoch 118/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1176 - accuracy: 0.9581 - val_loss: 0.6077 - val_accuracy: 0.8990\n",
      "Epoch 119/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1195 - accuracy: 0.9581 - val_loss: 0.6303 - val_accuracy: 0.8970\n",
      "Epoch 120/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1139 - accuracy: 0.9591 - val_loss: 0.5923 - val_accuracy: 0.8996\n",
      "Epoch 121/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1107 - accuracy: 0.9606 - val_loss: 0.6393 - val_accuracy: 0.8952\n",
      "Epoch 122/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1130 - accuracy: 0.9601 - val_loss: 0.6548 - val_accuracy: 0.8982\n",
      "Epoch 123/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1132 - accuracy: 0.9603 - val_loss: 0.6548 - val_accuracy: 0.8982\n",
      "Epoch 124/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1179 - accuracy: 0.9595 - val_loss: 0.6795 - val_accuracy: 0.8978\n",
      "Epoch 125/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1083 - accuracy: 0.9617 - val_loss: 0.6938 - val_accuracy: 0.8997\n",
      "Epoch 126/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1143 - accuracy: 0.9599 - val_loss: 0.6575 - val_accuracy: 0.8988\n",
      "Epoch 127/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1156 - accuracy: 0.9594 - val_loss: 0.6678 - val_accuracy: 0.8993\n",
      "Epoch 128/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1105 - accuracy: 0.9606 - val_loss: 0.6766 - val_accuracy: 0.8981\n",
      "Epoch 129/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1087 - accuracy: 0.9611 - val_loss: 0.7104 - val_accuracy: 0.8954\n",
      "Epoch 130/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1082 - accuracy: 0.9613 - val_loss: 0.6818 - val_accuracy: 0.8985\n",
      "Epoch 131/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1103 - accuracy: 0.9602 - val_loss: 0.6909 - val_accuracy: 0.9006\n",
      "Epoch 132/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1105 - accuracy: 0.9620 - val_loss: 0.7511 - val_accuracy: 0.8987\n",
      "Epoch 133/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1121 - accuracy: 0.9601 - val_loss: 0.7125 - val_accuracy: 0.8992\n",
      "Epoch 134/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.1142 - accuracy: 0.9614 - val_loss: 0.7370 - val_accuracy: 0.8963\n",
      "Epoch 135/1000\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1077 - accuracy: 0.9622 - val_loss: 0.7734 - val_accuracy: 0.8965\n",
      "Epoch 136/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.1087 - accuracy: 0.9616 - val_loss: 0.7315 - val_accuracy: 0.8972\n",
      "Epoch 137/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1113 - accuracy: 0.9625 - val_loss: 0.7068 - val_accuracy: 0.8990\n",
      "Epoch 138/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1068 - accuracy: 0.9628 - val_loss: 0.6713 - val_accuracy: 0.8974\n",
      "Epoch 139/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1124 - accuracy: 0.9610 - val_loss: 0.7391 - val_accuracy: 0.8996\n",
      "Epoch 140/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1096 - accuracy: 0.9609 - val_loss: 0.6879 - val_accuracy: 0.9014\n",
      "Epoch 141/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0986 - accuracy: 0.9639 - val_loss: 0.7138 - val_accuracy: 0.9002\n",
      "Epoch 142/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.1106 - accuracy: 0.9629 - val_loss: 0.8133 - val_accuracy: 0.9004\n",
      "Epoch 143/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1011 - accuracy: 0.9637 - val_loss: 0.7728 - val_accuracy: 0.8978\n",
      "Epoch 144/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1100 - accuracy: 0.9621 - val_loss: 0.7650 - val_accuracy: 0.9011\n",
      "Epoch 145/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.1124 - accuracy: 0.9626 - val_loss: 0.7449 - val_accuracy: 0.9001\n",
      "Epoch 146/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.1099 - accuracy: 0.9631 - val_loss: 0.7186 - val_accuracy: 0.9004\n",
      "Epoch 147/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1061 - accuracy: 0.9626 - val_loss: 0.6694 - val_accuracy: 0.9020\n",
      "Epoch 148/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.1025 - accuracy: 0.9629 - val_loss: 0.7594 - val_accuracy: 0.9043\n",
      "Epoch 149/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1055 - accuracy: 0.9639 - val_loss: 0.6923 - val_accuracy: 0.9023\n",
      "Epoch 150/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1058 - accuracy: 0.9637 - val_loss: 0.8208 - val_accuracy: 0.9023\n",
      "Epoch 151/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.1084 - accuracy: 0.9629 - val_loss: 0.7536 - val_accuracy: 0.8974\n",
      "Epoch 152/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1039 - accuracy: 0.9633 - val_loss: 0.8036 - val_accuracy: 0.8992\n",
      "Epoch 153/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0923 - accuracy: 0.9668 - val_loss: 0.8882 - val_accuracy: 0.8970\n",
      "Epoch 154/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.1062 - accuracy: 0.9635 - val_loss: 0.7922 - val_accuracy: 0.8998\n",
      "Epoch 155/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0996 - accuracy: 0.9653 - val_loss: 0.8262 - val_accuracy: 0.8918\n",
      "Epoch 156/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1040 - accuracy: 0.9642 - val_loss: 0.7955 - val_accuracy: 0.8955\n",
      "Epoch 157/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0988 - accuracy: 0.9650 - val_loss: 0.8651 - val_accuracy: 0.8967\n",
      "Epoch 158/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1060 - accuracy: 0.9630 - val_loss: 0.7960 - val_accuracy: 0.8990\n",
      "Epoch 159/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.1043 - accuracy: 0.9653 - val_loss: 0.8478 - val_accuracy: 0.8963\n",
      "Epoch 160/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0956 - accuracy: 0.9668 - val_loss: 0.8813 - val_accuracy: 0.9005\n",
      "Epoch 161/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1014 - accuracy: 0.9640 - val_loss: 0.7219 - val_accuracy: 0.8966\n",
      "Epoch 162/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1104 - accuracy: 0.9635 - val_loss: 0.8770 - val_accuracy: 0.8989\n",
      "Epoch 163/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1069 - accuracy: 0.9644 - val_loss: 0.8294 - val_accuracy: 0.9002\n",
      "Epoch 164/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0957 - accuracy: 0.9672 - val_loss: 0.7694 - val_accuracy: 0.8955\n",
      "Epoch 165/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0994 - accuracy: 0.9653 - val_loss: 0.8613 - val_accuracy: 0.8986\n",
      "Epoch 166/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1048 - accuracy: 0.9642 - val_loss: 0.7523 - val_accuracy: 0.9026\n",
      "Epoch 167/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.1001 - accuracy: 0.9657 - val_loss: 0.8322 - val_accuracy: 0.9004\n",
      "Epoch 168/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.1016 - accuracy: 0.9641 - val_loss: 0.7909 - val_accuracy: 0.8989\n",
      "Epoch 169/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1084 - accuracy: 0.9628 - val_loss: 0.8046 - val_accuracy: 0.8987\n",
      "Epoch 170/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1021 - accuracy: 0.9653 - val_loss: 0.7918 - val_accuracy: 0.8991\n",
      "Epoch 171/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0984 - accuracy: 0.9652 - val_loss: 0.8128 - val_accuracy: 0.9003\n",
      "Epoch 172/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0975 - accuracy: 0.9657 - val_loss: 0.7877 - val_accuracy: 0.8981\n",
      "Epoch 173/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0949 - accuracy: 0.9663 - val_loss: 0.8330 - val_accuracy: 0.8988\n",
      "Epoch 174/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0980 - accuracy: 0.9655 - val_loss: 0.7897 - val_accuracy: 0.8988\n",
      "Epoch 175/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0971 - accuracy: 0.9662 - val_loss: 0.8082 - val_accuracy: 0.8990\n",
      "Epoch 176/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.1028 - accuracy: 0.9663 - val_loss: 0.7844 - val_accuracy: 0.9000\n",
      "Epoch 177/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1001 - accuracy: 0.9656 - val_loss: 0.8198 - val_accuracy: 0.8958\n",
      "Epoch 178/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0927 - accuracy: 0.9675 - val_loss: 0.8565 - val_accuracy: 0.9052\n",
      "Epoch 179/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0933 - accuracy: 0.9684 - val_loss: 0.8750 - val_accuracy: 0.8984\n",
      "Epoch 180/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0960 - accuracy: 0.9671 - val_loss: 0.7963 - val_accuracy: 0.8992\n",
      "Epoch 181/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0937 - accuracy: 0.9675 - val_loss: 0.8630 - val_accuracy: 0.8992\n",
      "Epoch 182/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1025 - accuracy: 0.9654 - val_loss: 0.8445 - val_accuracy: 0.8977\n",
      "Epoch 183/1000\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0973 - accuracy: 0.9678 - val_loss: 0.8382 - val_accuracy: 0.8989\n",
      "Epoch 184/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0946 - accuracy: 0.9672 - val_loss: 0.8170 - val_accuracy: 0.8967\n",
      "Epoch 185/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0931 - accuracy: 0.9695 - val_loss: 0.9047 - val_accuracy: 0.8982\n",
      "Epoch 186/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0975 - accuracy: 0.9663 - val_loss: 0.8693 - val_accuracy: 0.8972\n",
      "Epoch 187/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0945 - accuracy: 0.9674 - val_loss: 0.9415 - val_accuracy: 0.8956\n",
      "Epoch 188/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0937 - accuracy: 0.9692 - val_loss: 0.7981 - val_accuracy: 0.8961\n",
      "Epoch 189/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1048 - accuracy: 0.9653 - val_loss: 0.8156 - val_accuracy: 0.8982\n",
      "Epoch 190/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0915 - accuracy: 0.9698 - val_loss: 0.9429 - val_accuracy: 0.8958\n",
      "Epoch 191/1000\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0946 - accuracy: 0.9672 - val_loss: 0.9733 - val_accuracy: 0.8965\n",
      "Epoch 192/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0928 - accuracy: 0.9689 - val_loss: 0.9033 - val_accuracy: 0.8988\n",
      "Epoch 193/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0876 - accuracy: 0.9696 - val_loss: 0.9372 - val_accuracy: 0.9007\n",
      "Epoch 194/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0973 - accuracy: 0.9681 - val_loss: 0.9582 - val_accuracy: 0.9005\n",
      "Epoch 195/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0930 - accuracy: 0.9680 - val_loss: 0.9644 - val_accuracy: 0.9006\n",
      "Epoch 196/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0898 - accuracy: 0.9684 - val_loss: 0.9310 - val_accuracy: 0.8992\n",
      "Epoch 197/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0947 - accuracy: 0.9686 - val_loss: 0.8566 - val_accuracy: 0.8974\n",
      "Epoch 198/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0974 - accuracy: 0.9688 - val_loss: 0.8861 - val_accuracy: 0.8982\n",
      "Epoch 199/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0901 - accuracy: 0.9697 - val_loss: 0.9560 - val_accuracy: 0.8994\n",
      "Epoch 200/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0909 - accuracy: 0.9690 - val_loss: 0.9331 - val_accuracy: 0.8984\n",
      "Epoch 201/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0993 - accuracy: 0.9664 - val_loss: 0.8795 - val_accuracy: 0.8996\n",
      "Epoch 202/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0846 - accuracy: 0.9698 - val_loss: 0.8918 - val_accuracy: 0.9024\n",
      "Epoch 203/1000\n",
      "1500/1500 [==============================] - 14s 10ms/step - loss: 0.0920 - accuracy: 0.9682 - val_loss: 0.7465 - val_accuracy: 0.8996\n",
      "Epoch 204/1000\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0959 - accuracy: 0.9676 - val_loss: 0.8108 - val_accuracy: 0.8921\n",
      "Epoch 205/1000\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0883 - accuracy: 0.9689 - val_loss: 0.8447 - val_accuracy: 0.9034\n",
      "Epoch 206/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0869 - accuracy: 0.9702 - val_loss: 0.8950 - val_accuracy: 0.8978\n",
      "Epoch 207/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0908 - accuracy: 0.9691 - val_loss: 0.9136 - val_accuracy: 0.8985\n",
      "Epoch 208/1000\n",
      "1500/1500 [==============================] - 16s 11ms/step - loss: 0.0929 - accuracy: 0.9693 - val_loss: 0.8134 - val_accuracy: 0.8992\n",
      "Epoch 209/1000\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0855 - accuracy: 0.9702 - val_loss: 0.8727 - val_accuracy: 0.8982\n",
      "Epoch 210/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0923 - accuracy: 0.9681 - val_loss: 0.8312 - val_accuracy: 0.8959\n",
      "Epoch 211/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0928 - accuracy: 0.9692 - val_loss: 0.9254 - val_accuracy: 0.8980\n",
      "Epoch 212/1000\n",
      "1500/1500 [==============================] - 14s 10ms/step - loss: 0.0943 - accuracy: 0.9693 - val_loss: 0.8016 - val_accuracy: 0.8993\n",
      "Epoch 213/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0853 - accuracy: 0.9700 - val_loss: 0.9113 - val_accuracy: 0.9000\n",
      "Epoch 214/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0906 - accuracy: 0.9690 - val_loss: 0.8350 - val_accuracy: 0.8996\n",
      "Epoch 215/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0945 - accuracy: 0.9687 - val_loss: 0.9057 - val_accuracy: 0.9018\n",
      "Epoch 216/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0872 - accuracy: 0.9713 - val_loss: 0.9160 - val_accuracy: 0.8945\n",
      "Epoch 217/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0899 - accuracy: 0.9701 - val_loss: 0.9546 - val_accuracy: 0.8988\n",
      "Epoch 218/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0826 - accuracy: 0.9710 - val_loss: 0.9821 - val_accuracy: 0.8985\n",
      "Epoch 219/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0856 - accuracy: 0.9701 - val_loss: 0.9735 - val_accuracy: 0.8977\n",
      "Epoch 220/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0919 - accuracy: 0.9691 - val_loss: 0.9829 - val_accuracy: 0.8945\n",
      "Epoch 221/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0943 - accuracy: 0.9696 - val_loss: 0.9892 - val_accuracy: 0.8972\n",
      "Epoch 222/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0889 - accuracy: 0.9719 - val_loss: 0.9612 - val_accuracy: 0.8988\n",
      "Epoch 223/1000\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0848 - accuracy: 0.9722 - val_loss: 0.9501 - val_accuracy: 0.8986\n",
      "Epoch 224/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0830 - accuracy: 0.9720 - val_loss: 0.9473 - val_accuracy: 0.9002\n",
      "Epoch 225/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0906 - accuracy: 0.9695 - val_loss: 1.0766 - val_accuracy: 0.8988\n",
      "Epoch 226/1000\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0870 - accuracy: 0.9713 - val_loss: 1.0643 - val_accuracy: 0.9006\n",
      "Epoch 227/1000\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0804 - accuracy: 0.9734 - val_loss: 0.8893 - val_accuracy: 0.8995\n",
      "Epoch 228/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0838 - accuracy: 0.9727 - val_loss: 1.0013 - val_accuracy: 0.8957\n",
      "Epoch 229/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0891 - accuracy: 0.9720 - val_loss: 1.0455 - val_accuracy: 0.8990\n",
      "Epoch 230/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0947 - accuracy: 0.9700 - val_loss: 0.8529 - val_accuracy: 0.8969\n",
      "Epoch 231/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0861 - accuracy: 0.9720 - val_loss: 0.9904 - val_accuracy: 0.8978\n",
      "Epoch 232/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0950 - accuracy: 0.9689 - val_loss: 0.9471 - val_accuracy: 0.8978\n",
      "Epoch 233/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0812 - accuracy: 0.9721 - val_loss: 1.0002 - val_accuracy: 0.9013\n",
      "Epoch 234/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0869 - accuracy: 0.9712 - val_loss: 0.9000 - val_accuracy: 0.8966\n",
      "Epoch 235/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0904 - accuracy: 0.9708 - val_loss: 0.8836 - val_accuracy: 0.9011\n",
      "Epoch 236/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.1053 - accuracy: 0.9686 - val_loss: 0.8980 - val_accuracy: 0.8988\n",
      "Epoch 237/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0785 - accuracy: 0.9726 - val_loss: 1.0086 - val_accuracy: 0.8982\n",
      "Epoch 238/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0913 - accuracy: 0.9709 - val_loss: 0.9626 - val_accuracy: 0.8999\n",
      "Epoch 239/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0820 - accuracy: 0.9722 - val_loss: 0.9534 - val_accuracy: 0.8970\n",
      "Epoch 240/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0867 - accuracy: 0.9718 - val_loss: 1.0873 - val_accuracy: 0.8989\n",
      "Epoch 241/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0876 - accuracy: 0.9714 - val_loss: 0.9332 - val_accuracy: 0.9017\n",
      "Epoch 242/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0947 - accuracy: 0.9703 - val_loss: 1.0542 - val_accuracy: 0.8975\n",
      "Epoch 243/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0899 - accuracy: 0.9722 - val_loss: 1.1285 - val_accuracy: 0.8964\n",
      "Epoch 244/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0873 - accuracy: 0.9721 - val_loss: 1.0915 - val_accuracy: 0.8997\n",
      "Epoch 245/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0867 - accuracy: 0.9710 - val_loss: 1.0828 - val_accuracy: 0.8967\n",
      "Epoch 246/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0851 - accuracy: 0.9718 - val_loss: 0.9239 - val_accuracy: 0.8980\n",
      "Epoch 247/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0802 - accuracy: 0.9723 - val_loss: 1.0578 - val_accuracy: 0.9028\n",
      "Epoch 248/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0883 - accuracy: 0.9724 - val_loss: 0.9726 - val_accuracy: 0.9014\n",
      "Epoch 249/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0832 - accuracy: 0.9723 - val_loss: 1.0126 - val_accuracy: 0.9014\n",
      "Epoch 250/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0778 - accuracy: 0.9732 - val_loss: 0.9762 - val_accuracy: 0.9000\n",
      "Epoch 251/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0872 - accuracy: 0.9723 - val_loss: 1.0783 - val_accuracy: 0.8984\n",
      "Epoch 252/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0759 - accuracy: 0.9742 - val_loss: 1.0325 - val_accuracy: 0.8988\n",
      "Epoch 253/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0898 - accuracy: 0.9709 - val_loss: 1.1169 - val_accuracy: 0.8998\n",
      "Epoch 254/1000\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0860 - accuracy: 0.9719 - val_loss: 1.0710 - val_accuracy: 0.8992\n",
      "Epoch 255/1000\n",
      "1500/1500 [==============================] - 16s 11ms/step - loss: 0.0837 - accuracy: 0.9727 - val_loss: 1.1476 - val_accuracy: 0.8989\n",
      "Epoch 256/1000\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0853 - accuracy: 0.9727 - val_loss: 1.1361 - val_accuracy: 0.9005\n",
      "Epoch 257/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0812 - accuracy: 0.9735 - val_loss: 1.1195 - val_accuracy: 0.8984\n",
      "Epoch 258/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0772 - accuracy: 0.9752 - val_loss: 1.2253 - val_accuracy: 0.8966\n",
      "Epoch 259/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0877 - accuracy: 0.9725 - val_loss: 1.1738 - val_accuracy: 0.8995\n",
      "Epoch 260/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0844 - accuracy: 0.9717 - val_loss: 1.1767 - val_accuracy: 0.8978\n",
      "Epoch 261/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0869 - accuracy: 0.9722 - val_loss: 1.1445 - val_accuracy: 0.8980\n",
      "Epoch 262/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0887 - accuracy: 0.9724 - val_loss: 1.1065 - val_accuracy: 0.9004\n",
      "Epoch 263/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0905 - accuracy: 0.9717 - val_loss: 1.0759 - val_accuracy: 0.9022\n",
      "Epoch 264/1000\n",
      "1500/1500 [==============================] - 14s 10ms/step - loss: 0.0809 - accuracy: 0.9730 - val_loss: 1.0129 - val_accuracy: 0.9028\n",
      "Epoch 265/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0847 - accuracy: 0.9729 - val_loss: 0.9812 - val_accuracy: 0.9025\n",
      "Epoch 266/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0802 - accuracy: 0.9743 - val_loss: 1.1074 - val_accuracy: 0.9003\n",
      "Epoch 267/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0795 - accuracy: 0.9738 - val_loss: 1.0202 - val_accuracy: 0.8994\n",
      "Epoch 268/1000\n",
      "1500/1500 [==============================] - 14s 10ms/step - loss: 0.0872 - accuracy: 0.9716 - val_loss: 0.9988 - val_accuracy: 0.8981\n",
      "Epoch 269/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0823 - accuracy: 0.9735 - val_loss: 1.1278 - val_accuracy: 0.8986\n",
      "Epoch 270/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0743 - accuracy: 0.9756 - val_loss: 1.2355 - val_accuracy: 0.8988\n",
      "Epoch 271/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0758 - accuracy: 0.9743 - val_loss: 1.1484 - val_accuracy: 0.8984\n",
      "Epoch 272/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0918 - accuracy: 0.9716 - val_loss: 1.0009 - val_accuracy: 0.8965\n",
      "Epoch 273/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0789 - accuracy: 0.9733 - val_loss: 1.1264 - val_accuracy: 0.8983\n",
      "Epoch 274/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0790 - accuracy: 0.9744 - val_loss: 1.1329 - val_accuracy: 0.8982\n",
      "Epoch 275/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0869 - accuracy: 0.9730 - val_loss: 1.1802 - val_accuracy: 0.8967\n",
      "Epoch 276/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0777 - accuracy: 0.9739 - val_loss: 1.1141 - val_accuracy: 0.8993\n",
      "Epoch 277/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0854 - accuracy: 0.9735 - val_loss: 1.1001 - val_accuracy: 0.9003\n",
      "Epoch 278/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0777 - accuracy: 0.9744 - val_loss: 1.0662 - val_accuracy: 0.8997\n",
      "Epoch 279/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0747 - accuracy: 0.9755 - val_loss: 1.1383 - val_accuracy: 0.8995\n",
      "Epoch 280/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0781 - accuracy: 0.9741 - val_loss: 1.0695 - val_accuracy: 0.9003\n",
      "Epoch 281/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0733 - accuracy: 0.9752 - val_loss: 1.2005 - val_accuracy: 0.8985\n",
      "Epoch 282/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0757 - accuracy: 0.9747 - val_loss: 1.2370 - val_accuracy: 0.9009\n",
      "Epoch 283/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0846 - accuracy: 0.9725 - val_loss: 1.1271 - val_accuracy: 0.9007\n",
      "Epoch 284/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0797 - accuracy: 0.9741 - val_loss: 1.1179 - val_accuracy: 0.8979\n",
      "Epoch 285/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0833 - accuracy: 0.9739 - val_loss: 1.2308 - val_accuracy: 0.8944\n",
      "Epoch 286/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0784 - accuracy: 0.9744 - val_loss: 1.1204 - val_accuracy: 0.9018\n",
      "Epoch 287/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0843 - accuracy: 0.9737 - val_loss: 1.1936 - val_accuracy: 0.8990\n",
      "Epoch 288/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0825 - accuracy: 0.9737 - val_loss: 1.2743 - val_accuracy: 0.9014\n",
      "Epoch 289/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0720 - accuracy: 0.9756 - val_loss: 1.1794 - val_accuracy: 0.8986\n",
      "Epoch 290/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0730 - accuracy: 0.9749 - val_loss: 1.2281 - val_accuracy: 0.8997\n",
      "Epoch 291/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0773 - accuracy: 0.9751 - val_loss: 1.1084 - val_accuracy: 0.9003\n",
      "Epoch 292/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0857 - accuracy: 0.9732 - val_loss: 1.0819 - val_accuracy: 0.8962\n",
      "Epoch 293/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0728 - accuracy: 0.9755 - val_loss: 1.1580 - val_accuracy: 0.8980\n",
      "Epoch 294/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0783 - accuracy: 0.9746 - val_loss: 1.1599 - val_accuracy: 0.8983\n",
      "Epoch 295/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0919 - accuracy: 0.9728 - val_loss: 1.2675 - val_accuracy: 0.9002\n",
      "Epoch 296/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0792 - accuracy: 0.9750 - val_loss: 1.1587 - val_accuracy: 0.9027\n",
      "Epoch 297/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0856 - accuracy: 0.9739 - val_loss: 1.1365 - val_accuracy: 0.8974\n",
      "Epoch 298/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0806 - accuracy: 0.9746 - val_loss: 1.2126 - val_accuracy: 0.8963\n",
      "Epoch 299/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0881 - accuracy: 0.9741 - val_loss: 1.2151 - val_accuracy: 0.8947\n",
      "Epoch 300/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0850 - accuracy: 0.9734 - val_loss: 1.1077 - val_accuracy: 0.8965\n",
      "Epoch 301/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0835 - accuracy: 0.9745 - val_loss: 1.2092 - val_accuracy: 0.8998\n",
      "Epoch 302/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0739 - accuracy: 0.9759 - val_loss: 1.1184 - val_accuracy: 0.8982\n",
      "Epoch 303/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0744 - accuracy: 0.9751 - val_loss: 1.3010 - val_accuracy: 0.8969\n",
      "Epoch 304/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0748 - accuracy: 0.9754 - val_loss: 1.2687 - val_accuracy: 0.8967\n",
      "Epoch 305/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0792 - accuracy: 0.9752 - val_loss: 1.4359 - val_accuracy: 0.8983\n",
      "Epoch 306/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0819 - accuracy: 0.9734 - val_loss: 1.3796 - val_accuracy: 0.8974\n",
      "Epoch 307/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0748 - accuracy: 0.9747 - val_loss: 1.2899 - val_accuracy: 0.8985\n",
      "Epoch 308/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0758 - accuracy: 0.9753 - val_loss: 1.4067 - val_accuracy: 0.8999\n",
      "Epoch 309/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0789 - accuracy: 0.9756 - val_loss: 1.4129 - val_accuracy: 0.8915\n",
      "Epoch 310/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0909 - accuracy: 0.9721 - val_loss: 1.3117 - val_accuracy: 0.8967\n",
      "Epoch 311/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0711 - accuracy: 0.9767 - val_loss: 1.1457 - val_accuracy: 0.8986\n",
      "Epoch 312/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0800 - accuracy: 0.9752 - val_loss: 1.2098 - val_accuracy: 0.8971\n",
      "Epoch 313/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0792 - accuracy: 0.9762 - val_loss: 1.1249 - val_accuracy: 0.8986\n",
      "Epoch 314/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0886 - accuracy: 0.9738 - val_loss: 1.0221 - val_accuracy: 0.8981\n",
      "Epoch 315/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0737 - accuracy: 0.9758 - val_loss: 1.1834 - val_accuracy: 0.8985\n",
      "Epoch 316/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0684 - accuracy: 0.9772 - val_loss: 1.3191 - val_accuracy: 0.8980\n",
      "Epoch 317/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0788 - accuracy: 0.9751 - val_loss: 1.1500 - val_accuracy: 0.9005\n",
      "Epoch 318/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0793 - accuracy: 0.9752 - val_loss: 1.1978 - val_accuracy: 0.8985\n",
      "Epoch 319/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0810 - accuracy: 0.9754 - val_loss: 1.2911 - val_accuracy: 0.9010\n",
      "Epoch 320/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0674 - accuracy: 0.9771 - val_loss: 1.3335 - val_accuracy: 0.8952\n",
      "Epoch 321/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0828 - accuracy: 0.9739 - val_loss: 1.1259 - val_accuracy: 0.8972\n",
      "Epoch 322/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0731 - accuracy: 0.9754 - val_loss: 1.2093 - val_accuracy: 0.8965\n",
      "Epoch 323/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0756 - accuracy: 0.9755 - val_loss: 1.3806 - val_accuracy: 0.9007\n",
      "Epoch 324/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0724 - accuracy: 0.9761 - val_loss: 1.3577 - val_accuracy: 0.8987\n",
      "Epoch 325/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0814 - accuracy: 0.9750 - val_loss: 1.2755 - val_accuracy: 0.9023\n",
      "Epoch 326/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0839 - accuracy: 0.9747 - val_loss: 1.2217 - val_accuracy: 0.8958\n",
      "Epoch 327/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0719 - accuracy: 0.9765 - val_loss: 1.3996 - val_accuracy: 0.8980\n",
      "Epoch 328/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0741 - accuracy: 0.9759 - val_loss: 1.2982 - val_accuracy: 0.8997\n",
      "Epoch 329/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0721 - accuracy: 0.9772 - val_loss: 1.3652 - val_accuracy: 0.8964\n",
      "Epoch 330/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0746 - accuracy: 0.9766 - val_loss: 1.2398 - val_accuracy: 0.8982\n",
      "Epoch 331/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0821 - accuracy: 0.9746 - val_loss: 1.3116 - val_accuracy: 0.8990\n",
      "Epoch 332/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0813 - accuracy: 0.9747 - val_loss: 1.5637 - val_accuracy: 0.8943\n",
      "Epoch 333/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0731 - accuracy: 0.9764 - val_loss: 1.2667 - val_accuracy: 0.8943\n",
      "Epoch 334/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0769 - accuracy: 0.9758 - val_loss: 1.3202 - val_accuracy: 0.8962\n",
      "Epoch 335/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0739 - accuracy: 0.9754 - val_loss: 1.4066 - val_accuracy: 0.8966\n",
      "Epoch 336/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0806 - accuracy: 0.9743 - val_loss: 1.4298 - val_accuracy: 0.8972\n",
      "Epoch 337/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0756 - accuracy: 0.9762 - val_loss: 1.2614 - val_accuracy: 0.8997\n",
      "Epoch 338/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0746 - accuracy: 0.9772 - val_loss: 1.4469 - val_accuracy: 0.8973\n",
      "Epoch 339/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0784 - accuracy: 0.9763 - val_loss: 1.5358 - val_accuracy: 0.8966\n",
      "Epoch 340/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0697 - accuracy: 0.9784 - val_loss: 1.6080 - val_accuracy: 0.9007\n",
      "Epoch 341/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0699 - accuracy: 0.9768 - val_loss: 1.3534 - val_accuracy: 0.8978\n",
      "Epoch 342/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0787 - accuracy: 0.9759 - val_loss: 1.5287 - val_accuracy: 0.8975\n",
      "Epoch 343/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0697 - accuracy: 0.9764 - val_loss: 1.3077 - val_accuracy: 0.8990\n",
      "Epoch 344/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0749 - accuracy: 0.9767 - val_loss: 1.3798 - val_accuracy: 0.8991\n",
      "Epoch 345/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0736 - accuracy: 0.9765 - val_loss: 1.3444 - val_accuracy: 0.8984\n",
      "Epoch 346/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0715 - accuracy: 0.9781 - val_loss: 1.4323 - val_accuracy: 0.8993\n",
      "Epoch 347/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0739 - accuracy: 0.9768 - val_loss: 1.2457 - val_accuracy: 0.8997\n",
      "Epoch 348/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0800 - accuracy: 0.9766 - val_loss: 1.2012 - val_accuracy: 0.8999\n",
      "Epoch 349/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0720 - accuracy: 0.9771 - val_loss: 1.3812 - val_accuracy: 0.9005\n",
      "Epoch 350/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0784 - accuracy: 0.9759 - val_loss: 1.3895 - val_accuracy: 0.9001\n",
      "Epoch 351/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0708 - accuracy: 0.9776 - val_loss: 1.3903 - val_accuracy: 0.8971\n",
      "Epoch 352/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0747 - accuracy: 0.9763 - val_loss: 1.4570 - val_accuracy: 0.8960\n",
      "Epoch 353/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0686 - accuracy: 0.9779 - val_loss: 1.4744 - val_accuracy: 0.8988\n",
      "Epoch 354/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0730 - accuracy: 0.9782 - val_loss: 1.4380 - val_accuracy: 0.9002\n",
      "Epoch 355/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0747 - accuracy: 0.9767 - val_loss: 1.5925 - val_accuracy: 0.8986\n",
      "Epoch 356/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0766 - accuracy: 0.9763 - val_loss: 1.3687 - val_accuracy: 0.8988\n",
      "Epoch 357/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0698 - accuracy: 0.9776 - val_loss: 1.3813 - val_accuracy: 0.9007\n",
      "Epoch 358/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0674 - accuracy: 0.9784 - val_loss: 1.5838 - val_accuracy: 0.8997\n",
      "Epoch 359/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0826 - accuracy: 0.9759 - val_loss: 1.4888 - val_accuracy: 0.8974\n",
      "Epoch 360/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0794 - accuracy: 0.9761 - val_loss: 1.4137 - val_accuracy: 0.9000\n",
      "Epoch 361/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0725 - accuracy: 0.9774 - val_loss: 1.3910 - val_accuracy: 0.8957\n",
      "Epoch 362/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0776 - accuracy: 0.9761 - val_loss: 1.4840 - val_accuracy: 0.8988\n",
      "Epoch 363/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0748 - accuracy: 0.9775 - val_loss: 1.4938 - val_accuracy: 0.8946\n",
      "Epoch 364/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0780 - accuracy: 0.9763 - val_loss: 1.5278 - val_accuracy: 0.9011\n",
      "Epoch 365/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0735 - accuracy: 0.9777 - val_loss: 1.4012 - val_accuracy: 0.9005\n",
      "Epoch 366/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0691 - accuracy: 0.9784 - val_loss: 1.2266 - val_accuracy: 0.8978\n",
      "Epoch 367/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0726 - accuracy: 0.9772 - val_loss: 1.3696 - val_accuracy: 0.9013\n",
      "Epoch 368/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0795 - accuracy: 0.9748 - val_loss: 1.2901 - val_accuracy: 0.8992\n",
      "Epoch 369/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0755 - accuracy: 0.9761 - val_loss: 1.2403 - val_accuracy: 0.8975\n",
      "Epoch 370/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0709 - accuracy: 0.9776 - val_loss: 1.3870 - val_accuracy: 0.9006\n",
      "Epoch 371/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0756 - accuracy: 0.9761 - val_loss: 1.4350 - val_accuracy: 0.8988\n",
      "Epoch 372/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0687 - accuracy: 0.9777 - val_loss: 1.4555 - val_accuracy: 0.8963\n",
      "Epoch 373/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0694 - accuracy: 0.9778 - val_loss: 1.4242 - val_accuracy: 0.9005\n",
      "Epoch 374/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0648 - accuracy: 0.9778 - val_loss: 1.6858 - val_accuracy: 0.8956\n",
      "Epoch 375/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0769 - accuracy: 0.9767 - val_loss: 1.5561 - val_accuracy: 0.8991\n",
      "Epoch 376/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0741 - accuracy: 0.9764 - val_loss: 1.4418 - val_accuracy: 0.8988\n",
      "Epoch 377/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0800 - accuracy: 0.9756 - val_loss: 1.4706 - val_accuracy: 0.8995\n",
      "Epoch 378/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0820 - accuracy: 0.9746 - val_loss: 1.4234 - val_accuracy: 0.8996\n",
      "Epoch 379/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0669 - accuracy: 0.9780 - val_loss: 1.3991 - val_accuracy: 0.8978\n",
      "Epoch 380/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0741 - accuracy: 0.9778 - val_loss: 1.4129 - val_accuracy: 0.8980\n",
      "Epoch 381/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0659 - accuracy: 0.9785 - val_loss: 1.4337 - val_accuracy: 0.8993\n",
      "Epoch 382/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0722 - accuracy: 0.9780 - val_loss: 1.4316 - val_accuracy: 0.9007\n",
      "Epoch 383/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0845 - accuracy: 0.9755 - val_loss: 1.5182 - val_accuracy: 0.8964\n",
      "Epoch 384/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0722 - accuracy: 0.9776 - val_loss: 1.3611 - val_accuracy: 0.8985\n",
      "Epoch 385/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0710 - accuracy: 0.9784 - val_loss: 1.3653 - val_accuracy: 0.8980\n",
      "Epoch 386/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0706 - accuracy: 0.9786 - val_loss: 1.3790 - val_accuracy: 0.8987\n",
      "Epoch 387/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0755 - accuracy: 0.9762 - val_loss: 1.3141 - val_accuracy: 0.9003\n",
      "Epoch 388/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0718 - accuracy: 0.9783 - val_loss: 1.3918 - val_accuracy: 0.8928\n",
      "Epoch 389/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0694 - accuracy: 0.9779 - val_loss: 1.3985 - val_accuracy: 0.8994\n",
      "Epoch 390/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0798 - accuracy: 0.9758 - val_loss: 1.5427 - val_accuracy: 0.8956\n",
      "Epoch 391/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0645 - accuracy: 0.9787 - val_loss: 1.4481 - val_accuracy: 0.8982\n",
      "Epoch 392/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0831 - accuracy: 0.9775 - val_loss: 1.4079 - val_accuracy: 0.9007\n",
      "Epoch 393/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0701 - accuracy: 0.9786 - val_loss: 1.3816 - val_accuracy: 0.8975\n",
      "Epoch 394/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0819 - accuracy: 0.9759 - val_loss: 1.4409 - val_accuracy: 0.8975\n",
      "Epoch 395/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0725 - accuracy: 0.9796 - val_loss: 1.5563 - val_accuracy: 0.8992\n",
      "Epoch 396/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0933 - accuracy: 0.9748 - val_loss: 1.4043 - val_accuracy: 0.8969\n",
      "Epoch 397/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0755 - accuracy: 0.9782 - val_loss: 1.5136 - val_accuracy: 0.8990\n",
      "Epoch 398/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0751 - accuracy: 0.9781 - val_loss: 1.3429 - val_accuracy: 0.8957\n",
      "Epoch 399/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0646 - accuracy: 0.9782 - val_loss: 1.4436 - val_accuracy: 0.8996\n",
      "Epoch 400/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0705 - accuracy: 0.9785 - val_loss: 1.4804 - val_accuracy: 0.8978\n",
      "Epoch 401/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0634 - accuracy: 0.9796 - val_loss: 1.5165 - val_accuracy: 0.8962\n",
      "Epoch 402/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0696 - accuracy: 0.9779 - val_loss: 1.3822 - val_accuracy: 0.8966\n",
      "Epoch 403/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0703 - accuracy: 0.9774 - val_loss: 1.5732 - val_accuracy: 0.8979\n",
      "Epoch 404/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0696 - accuracy: 0.9783 - val_loss: 1.5372 - val_accuracy: 0.8961\n",
      "Epoch 405/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0744 - accuracy: 0.9773 - val_loss: 1.6045 - val_accuracy: 0.8985\n",
      "Epoch 406/1000\n",
      "1500/1500 [==============================] - 14s 10ms/step - loss: 0.0653 - accuracy: 0.9798 - val_loss: 1.5416 - val_accuracy: 0.8983\n",
      "Epoch 407/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0694 - accuracy: 0.9781 - val_loss: 1.7306 - val_accuracy: 0.8980\n",
      "Epoch 408/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0689 - accuracy: 0.9788 - val_loss: 1.3631 - val_accuracy: 0.8979\n",
      "Epoch 409/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0701 - accuracy: 0.9780 - val_loss: 1.6033 - val_accuracy: 0.8964\n",
      "Epoch 410/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0632 - accuracy: 0.9794 - val_loss: 1.6483 - val_accuracy: 0.8972\n",
      "Epoch 411/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0617 - accuracy: 0.9802 - val_loss: 1.6457 - val_accuracy: 0.9012\n",
      "Epoch 412/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0667 - accuracy: 0.9789 - val_loss: 1.3786 - val_accuracy: 0.8988\n",
      "Epoch 413/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0670 - accuracy: 0.9792 - val_loss: 1.4505 - val_accuracy: 0.8955\n",
      "Epoch 414/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0717 - accuracy: 0.9784 - val_loss: 1.6469 - val_accuracy: 0.8988\n",
      "Epoch 415/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0700 - accuracy: 0.9786 - val_loss: 1.4501 - val_accuracy: 0.8980\n",
      "Epoch 416/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0688 - accuracy: 0.9789 - val_loss: 1.5226 - val_accuracy: 0.8977\n",
      "Epoch 417/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0775 - accuracy: 0.9777 - val_loss: 1.6011 - val_accuracy: 0.8917\n",
      "Epoch 418/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0750 - accuracy: 0.9770 - val_loss: 1.3655 - val_accuracy: 0.8978\n",
      "Epoch 419/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0701 - accuracy: 0.9780 - val_loss: 1.4946 - val_accuracy: 0.8982\n",
      "Epoch 420/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0655 - accuracy: 0.9798 - val_loss: 1.6891 - val_accuracy: 0.8931\n",
      "Epoch 421/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0774 - accuracy: 0.9767 - val_loss: 1.3428 - val_accuracy: 0.9007\n",
      "Epoch 422/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0758 - accuracy: 0.9770 - val_loss: 1.5950 - val_accuracy: 0.8977\n",
      "Epoch 423/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0651 - accuracy: 0.9805 - val_loss: 1.4855 - val_accuracy: 0.8987\n",
      "Epoch 424/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0695 - accuracy: 0.9798 - val_loss: 1.6423 - val_accuracy: 0.8963\n",
      "Epoch 425/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0665 - accuracy: 0.9797 - val_loss: 1.7070 - val_accuracy: 0.8980\n",
      "Epoch 426/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0625 - accuracy: 0.9792 - val_loss: 1.7694 - val_accuracy: 0.8982\n",
      "Epoch 427/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0685 - accuracy: 0.9785 - val_loss: 1.4296 - val_accuracy: 0.8917\n",
      "Epoch 428/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0806 - accuracy: 0.9781 - val_loss: 1.5707 - val_accuracy: 0.8928\n",
      "Epoch 429/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0645 - accuracy: 0.9794 - val_loss: 1.3821 - val_accuracy: 0.8988\n",
      "Epoch 430/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0672 - accuracy: 0.9795 - val_loss: 1.4700 - val_accuracy: 0.8982\n",
      "Epoch 431/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0665 - accuracy: 0.9798 - val_loss: 1.5227 - val_accuracy: 0.8942\n",
      "Epoch 432/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0738 - accuracy: 0.9779 - val_loss: 1.5526 - val_accuracy: 0.8996\n",
      "Epoch 433/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0656 - accuracy: 0.9789 - val_loss: 1.6331 - val_accuracy: 0.8997\n",
      "Epoch 434/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0686 - accuracy: 0.9792 - val_loss: 1.4781 - val_accuracy: 0.8965\n",
      "Epoch 435/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0880 - accuracy: 0.9771 - val_loss: 1.6340 - val_accuracy: 0.8971\n",
      "Epoch 436/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0632 - accuracy: 0.9815 - val_loss: 1.5648 - val_accuracy: 0.8991\n",
      "Epoch 437/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0643 - accuracy: 0.9804 - val_loss: 1.6879 - val_accuracy: 0.8972\n",
      "Epoch 438/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0677 - accuracy: 0.9795 - val_loss: 1.7637 - val_accuracy: 0.8992\n",
      "Epoch 439/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0685 - accuracy: 0.9793 - val_loss: 1.6015 - val_accuracy: 0.8991\n",
      "Epoch 440/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0640 - accuracy: 0.9799 - val_loss: 1.8624 - val_accuracy: 0.8954\n",
      "Epoch 441/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0691 - accuracy: 0.9793 - val_loss: 1.6240 - val_accuracy: 0.8963\n",
      "Epoch 442/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0650 - accuracy: 0.9795 - val_loss: 1.7699 - val_accuracy: 0.8948\n",
      "Epoch 443/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0675 - accuracy: 0.9800 - val_loss: 1.4899 - val_accuracy: 0.8971\n",
      "Epoch 444/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0698 - accuracy: 0.9802 - val_loss: 1.5146 - val_accuracy: 0.9016\n",
      "Epoch 445/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0663 - accuracy: 0.9798 - val_loss: 1.6411 - val_accuracy: 0.9013\n",
      "Epoch 446/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0563 - accuracy: 0.9824 - val_loss: 1.4276 - val_accuracy: 0.8967\n",
      "Epoch 447/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0653 - accuracy: 0.9800 - val_loss: 1.4961 - val_accuracy: 0.8954\n",
      "Epoch 448/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0608 - accuracy: 0.9813 - val_loss: 1.4277 - val_accuracy: 0.8936\n",
      "Epoch 449/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0747 - accuracy: 0.9783 - val_loss: 1.5754 - val_accuracy: 0.8984\n",
      "Epoch 450/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0664 - accuracy: 0.9807 - val_loss: 1.5540 - val_accuracy: 0.9001\n",
      "Epoch 451/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0612 - accuracy: 0.9805 - val_loss: 1.7742 - val_accuracy: 0.8986\n",
      "Epoch 452/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0641 - accuracy: 0.9792 - val_loss: 1.6881 - val_accuracy: 0.8969\n",
      "Epoch 453/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0651 - accuracy: 0.9801 - val_loss: 1.8055 - val_accuracy: 0.8992\n",
      "Epoch 454/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0632 - accuracy: 0.9816 - val_loss: 1.6784 - val_accuracy: 0.9000\n",
      "Epoch 455/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0717 - accuracy: 0.9796 - val_loss: 1.6173 - val_accuracy: 0.8943\n",
      "Epoch 456/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0713 - accuracy: 0.9779 - val_loss: 1.5337 - val_accuracy: 0.8994\n",
      "Epoch 457/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0625 - accuracy: 0.9802 - val_loss: 1.6123 - val_accuracy: 0.8961\n",
      "Epoch 458/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0687 - accuracy: 0.9793 - val_loss: 1.7697 - val_accuracy: 0.8964\n",
      "Epoch 459/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0732 - accuracy: 0.9785 - val_loss: 1.6897 - val_accuracy: 0.9000\n",
      "Epoch 460/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0717 - accuracy: 0.9801 - val_loss: 1.8250 - val_accuracy: 0.8975\n",
      "Epoch 461/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0634 - accuracy: 0.9800 - val_loss: 1.5395 - val_accuracy: 0.8914\n",
      "Epoch 462/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0670 - accuracy: 0.9790 - val_loss: 1.5374 - val_accuracy: 0.8957\n",
      "Epoch 463/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0653 - accuracy: 0.9805 - val_loss: 1.7022 - val_accuracy: 0.8994\n",
      "Epoch 464/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0639 - accuracy: 0.9797 - val_loss: 1.7055 - val_accuracy: 0.8982\n",
      "Epoch 465/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1044 - accuracy: 0.9771 - val_loss: 1.4279 - val_accuracy: 0.8974\n",
      "Epoch 466/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0637 - accuracy: 0.9803 - val_loss: 1.5521 - val_accuracy: 0.8997\n",
      "Epoch 467/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0579 - accuracy: 0.9810 - val_loss: 1.6021 - val_accuracy: 0.9002\n",
      "Epoch 468/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0645 - accuracy: 0.9797 - val_loss: 1.4835 - val_accuracy: 0.8974\n",
      "Epoch 469/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0603 - accuracy: 0.9808 - val_loss: 1.7748 - val_accuracy: 0.9000\n",
      "Epoch 470/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0586 - accuracy: 0.9811 - val_loss: 1.7139 - val_accuracy: 0.8944\n",
      "Epoch 471/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0690 - accuracy: 0.9790 - val_loss: 1.8072 - val_accuracy: 0.9001\n",
      "Epoch 472/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0625 - accuracy: 0.9804 - val_loss: 1.7860 - val_accuracy: 0.8990\n",
      "Epoch 473/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0774 - accuracy: 0.9789 - val_loss: 1.6739 - val_accuracy: 0.8947\n",
      "Epoch 474/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0690 - accuracy: 0.9793 - val_loss: 1.7619 - val_accuracy: 0.8963\n",
      "Epoch 475/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0945 - accuracy: 0.9801 - val_loss: 1.4813 - val_accuracy: 0.8997\n",
      "Epoch 476/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0578 - accuracy: 0.9822 - val_loss: 1.7840 - val_accuracy: 0.9008\n",
      "Epoch 477/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0730 - accuracy: 0.9789 - val_loss: 1.6262 - val_accuracy: 0.8969\n",
      "Epoch 478/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0675 - accuracy: 0.9805 - val_loss: 1.6303 - val_accuracy: 0.8983\n",
      "Epoch 479/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0647 - accuracy: 0.9813 - val_loss: 1.7828 - val_accuracy: 0.8933\n",
      "Epoch 480/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0748 - accuracy: 0.9794 - val_loss: 1.5426 - val_accuracy: 0.8982\n",
      "Epoch 481/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0637 - accuracy: 0.9807 - val_loss: 1.6642 - val_accuracy: 0.8955\n",
      "Epoch 482/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0688 - accuracy: 0.9794 - val_loss: 1.6419 - val_accuracy: 0.8988\n",
      "Epoch 483/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0671 - accuracy: 0.9796 - val_loss: 1.7432 - val_accuracy: 0.9020\n",
      "Epoch 484/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0647 - accuracy: 0.9805 - val_loss: 1.9090 - val_accuracy: 0.8963\n",
      "Epoch 485/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0656 - accuracy: 0.9803 - val_loss: 1.7532 - val_accuracy: 0.8986\n",
      "Epoch 486/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0616 - accuracy: 0.9817 - val_loss: 1.9026 - val_accuracy: 0.8964\n",
      "Epoch 487/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0662 - accuracy: 0.9800 - val_loss: 2.0367 - val_accuracy: 0.8991\n",
      "Epoch 488/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0727 - accuracy: 0.9796 - val_loss: 1.6027 - val_accuracy: 0.8997\n",
      "Epoch 489/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0619 - accuracy: 0.9815 - val_loss: 1.7858 - val_accuracy: 0.8978\n",
      "Epoch 490/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0589 - accuracy: 0.9815 - val_loss: 1.8620 - val_accuracy: 0.8947\n",
      "Epoch 491/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0645 - accuracy: 0.9799 - val_loss: 1.7258 - val_accuracy: 0.8977\n",
      "Epoch 492/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0619 - accuracy: 0.9806 - val_loss: 1.7612 - val_accuracy: 0.8962\n",
      "Epoch 493/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0654 - accuracy: 0.9798 - val_loss: 1.7207 - val_accuracy: 0.8996\n",
      "Epoch 494/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0619 - accuracy: 0.9815 - val_loss: 1.8196 - val_accuracy: 0.8959\n",
      "Epoch 495/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0679 - accuracy: 0.9805 - val_loss: 1.6302 - val_accuracy: 0.8980\n",
      "Epoch 496/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0630 - accuracy: 0.9801 - val_loss: 1.8020 - val_accuracy: 0.8982\n",
      "Epoch 497/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0588 - accuracy: 0.9816 - val_loss: 1.6436 - val_accuracy: 0.8965\n",
      "Epoch 498/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0559 - accuracy: 0.9827 - val_loss: 1.6476 - val_accuracy: 0.8992\n",
      "Epoch 499/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0615 - accuracy: 0.9804 - val_loss: 1.6728 - val_accuracy: 0.9010\n",
      "Epoch 500/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0615 - accuracy: 0.9816 - val_loss: 1.8661 - val_accuracy: 0.8964\n",
      "Epoch 501/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0607 - accuracy: 0.9810 - val_loss: 1.7600 - val_accuracy: 0.8960\n",
      "Epoch 502/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0703 - accuracy: 0.9797 - val_loss: 1.7949 - val_accuracy: 0.8982\n",
      "Epoch 503/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0593 - accuracy: 0.9815 - val_loss: 1.9588 - val_accuracy: 0.8993\n",
      "Epoch 504/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0745 - accuracy: 0.9793 - val_loss: 1.5060 - val_accuracy: 0.8979\n",
      "Epoch 505/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0612 - accuracy: 0.9816 - val_loss: 1.6588 - val_accuracy: 0.8973\n",
      "Epoch 506/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0736 - accuracy: 0.9804 - val_loss: 2.0177 - val_accuracy: 0.8943\n",
      "Epoch 507/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0682 - accuracy: 0.9815 - val_loss: 1.9287 - val_accuracy: 0.8986\n",
      "Epoch 508/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0738 - accuracy: 0.9795 - val_loss: 1.9869 - val_accuracy: 0.8982\n",
      "Epoch 509/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0625 - accuracy: 0.9816 - val_loss: 1.8189 - val_accuracy: 0.8975\n",
      "Epoch 510/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0679 - accuracy: 0.9822 - val_loss: 1.9353 - val_accuracy: 0.8988\n",
      "Epoch 511/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0799 - accuracy: 0.9795 - val_loss: 1.7121 - val_accuracy: 0.8977\n",
      "Epoch 512/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0549 - accuracy: 0.9827 - val_loss: 1.7544 - val_accuracy: 0.8982\n",
      "Epoch 513/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0714 - accuracy: 0.9792 - val_loss: 1.8846 - val_accuracy: 0.8947\n",
      "Epoch 514/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0568 - accuracy: 0.9823 - val_loss: 1.8564 - val_accuracy: 0.9025\n",
      "Epoch 515/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0638 - accuracy: 0.9807 - val_loss: 1.7743 - val_accuracy: 0.8999\n",
      "Epoch 516/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0558 - accuracy: 0.9823 - val_loss: 1.7878 - val_accuracy: 0.8975\n",
      "Epoch 517/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0708 - accuracy: 0.9805 - val_loss: 1.8404 - val_accuracy: 0.8995\n",
      "Epoch 518/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0691 - accuracy: 0.9808 - val_loss: 1.6919 - val_accuracy: 0.8978\n",
      "Epoch 519/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0684 - accuracy: 0.9814 - val_loss: 1.8013 - val_accuracy: 0.8975\n",
      "Epoch 520/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0729 - accuracy: 0.9794 - val_loss: 2.0010 - val_accuracy: 0.8989\n",
      "Epoch 521/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0679 - accuracy: 0.9812 - val_loss: 1.6397 - val_accuracy: 0.8992\n",
      "Epoch 522/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0670 - accuracy: 0.9803 - val_loss: 1.7734 - val_accuracy: 0.8992\n",
      "Epoch 523/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0603 - accuracy: 0.9829 - val_loss: 2.0178 - val_accuracy: 0.9013\n",
      "Epoch 524/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0584 - accuracy: 0.9822 - val_loss: 1.7983 - val_accuracy: 0.8948\n",
      "Epoch 525/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0668 - accuracy: 0.9806 - val_loss: 1.8453 - val_accuracy: 0.8993\n",
      "Epoch 526/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0673 - accuracy: 0.9806 - val_loss: 1.7714 - val_accuracy: 0.8964\n",
      "Epoch 527/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0674 - accuracy: 0.9803 - val_loss: 1.7270 - val_accuracy: 0.8999\n",
      "Epoch 528/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0597 - accuracy: 0.9827 - val_loss: 1.8405 - val_accuracy: 0.8998\n",
      "Epoch 529/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0611 - accuracy: 0.9810 - val_loss: 1.8135 - val_accuracy: 0.8987\n",
      "Epoch 530/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0513 - accuracy: 0.9832 - val_loss: 1.9238 - val_accuracy: 0.8983\n",
      "Epoch 531/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0673 - accuracy: 0.9811 - val_loss: 1.8590 - val_accuracy: 0.8967\n",
      "Epoch 532/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0617 - accuracy: 0.9814 - val_loss: 1.6654 - val_accuracy: 0.8997\n",
      "Epoch 533/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0598 - accuracy: 0.9820 - val_loss: 2.0122 - val_accuracy: 0.8977\n",
      "Epoch 534/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0591 - accuracy: 0.9816 - val_loss: 1.8411 - val_accuracy: 0.8976\n",
      "Epoch 535/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0686 - accuracy: 0.9804 - val_loss: 1.8912 - val_accuracy: 0.8978\n",
      "Epoch 536/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0649 - accuracy: 0.9814 - val_loss: 1.7460 - val_accuracy: 0.8972\n",
      "Epoch 537/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0490 - accuracy: 0.9846 - val_loss: 1.9525 - val_accuracy: 0.9016\n",
      "Epoch 538/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0677 - accuracy: 0.9803 - val_loss: 1.8036 - val_accuracy: 0.8953\n",
      "Epoch 539/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0626 - accuracy: 0.9811 - val_loss: 1.5195 - val_accuracy: 0.8979\n",
      "Epoch 540/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0599 - accuracy: 0.9830 - val_loss: 1.5454 - val_accuracy: 0.8999\n",
      "Epoch 541/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0545 - accuracy: 0.9823 - val_loss: 1.8527 - val_accuracy: 0.8991\n",
      "Epoch 542/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0634 - accuracy: 0.9821 - val_loss: 1.7261 - val_accuracy: 0.9013\n",
      "Epoch 543/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0715 - accuracy: 0.9789 - val_loss: 1.8688 - val_accuracy: 0.9026\n",
      "Epoch 544/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0610 - accuracy: 0.9820 - val_loss: 1.9485 - val_accuracy: 0.8968\n",
      "Epoch 545/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0651 - accuracy: 0.9819 - val_loss: 1.8856 - val_accuracy: 0.8962\n",
      "Epoch 546/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0628 - accuracy: 0.9814 - val_loss: 1.8577 - val_accuracy: 0.9001\n",
      "Epoch 547/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0480 - accuracy: 0.9841 - val_loss: 1.8382 - val_accuracy: 0.9017\n",
      "Epoch 548/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0652 - accuracy: 0.9810 - val_loss: 2.0150 - val_accuracy: 0.8984\n",
      "Epoch 549/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0656 - accuracy: 0.9806 - val_loss: 2.0100 - val_accuracy: 0.8978\n",
      "Epoch 550/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0580 - accuracy: 0.9826 - val_loss: 1.8326 - val_accuracy: 0.8991\n",
      "Epoch 551/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0604 - accuracy: 0.9824 - val_loss: 1.8570 - val_accuracy: 0.8982\n",
      "Epoch 552/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0724 - accuracy: 0.9805 - val_loss: 1.7411 - val_accuracy: 0.8945\n",
      "Epoch 553/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0635 - accuracy: 0.9822 - val_loss: 1.7218 - val_accuracy: 0.9000\n",
      "Epoch 554/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0612 - accuracy: 0.9812 - val_loss: 1.8914 - val_accuracy: 0.8980\n",
      "Epoch 555/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0654 - accuracy: 0.9819 - val_loss: 1.7601 - val_accuracy: 0.8998\n",
      "Epoch 556/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0577 - accuracy: 0.9822 - val_loss: 2.0053 - val_accuracy: 0.9014\n",
      "Epoch 557/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0644 - accuracy: 0.9813 - val_loss: 1.9900 - val_accuracy: 0.8982\n",
      "Epoch 558/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0682 - accuracy: 0.9814 - val_loss: 1.8340 - val_accuracy: 0.8995\n",
      "Epoch 559/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0619 - accuracy: 0.9826 - val_loss: 1.8948 - val_accuracy: 0.8976\n",
      "Epoch 560/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0618 - accuracy: 0.9815 - val_loss: 1.7653 - val_accuracy: 0.9003\n",
      "Epoch 561/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0522 - accuracy: 0.9832 - val_loss: 1.9601 - val_accuracy: 0.9013\n",
      "Epoch 562/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0622 - accuracy: 0.9829 - val_loss: 1.9409 - val_accuracy: 0.8993\n",
      "Epoch 563/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0681 - accuracy: 0.9809 - val_loss: 1.7259 - val_accuracy: 0.8978\n",
      "Epoch 564/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0654 - accuracy: 0.9814 - val_loss: 1.7404 - val_accuracy: 0.8984\n",
      "Epoch 565/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0663 - accuracy: 0.9820 - val_loss: 1.8269 - val_accuracy: 0.8957\n",
      "Epoch 566/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0700 - accuracy: 0.9819 - val_loss: 1.9131 - val_accuracy: 0.9006\n",
      "Epoch 567/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0587 - accuracy: 0.9819 - val_loss: 1.9080 - val_accuracy: 0.8992\n",
      "Epoch 568/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0631 - accuracy: 0.9816 - val_loss: 1.9281 - val_accuracy: 0.9023\n",
      "Epoch 569/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0593 - accuracy: 0.9819 - val_loss: 1.8357 - val_accuracy: 0.8978\n",
      "Epoch 570/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0754 - accuracy: 0.9802 - val_loss: 1.9184 - val_accuracy: 0.8977\n",
      "Epoch 571/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0634 - accuracy: 0.9828 - val_loss: 1.8792 - val_accuracy: 0.9007\n",
      "Epoch 572/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0563 - accuracy: 0.9833 - val_loss: 1.8006 - val_accuracy: 0.8964\n",
      "Epoch 573/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0571 - accuracy: 0.9824 - val_loss: 1.8984 - val_accuracy: 0.8982\n",
      "Epoch 574/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0621 - accuracy: 0.9819 - val_loss: 2.0309 - val_accuracy: 0.8997\n",
      "Epoch 575/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0657 - accuracy: 0.9806 - val_loss: 1.9021 - val_accuracy: 0.9028\n",
      "Epoch 576/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0655 - accuracy: 0.9809 - val_loss: 2.0131 - val_accuracy: 0.8960\n",
      "Epoch 577/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0583 - accuracy: 0.9829 - val_loss: 2.0840 - val_accuracy: 0.9007\n",
      "Epoch 578/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0554 - accuracy: 0.9833 - val_loss: 1.9598 - val_accuracy: 0.9014\n",
      "Epoch 579/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0680 - accuracy: 0.9821 - val_loss: 1.8847 - val_accuracy: 0.8992\n",
      "Epoch 580/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0591 - accuracy: 0.9825 - val_loss: 1.7363 - val_accuracy: 0.8977\n",
      "Epoch 581/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0536 - accuracy: 0.9829 - val_loss: 2.0204 - val_accuracy: 0.9000\n",
      "Epoch 582/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0517 - accuracy: 0.9838 - val_loss: 1.9660 - val_accuracy: 0.8987\n",
      "Epoch 583/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0720 - accuracy: 0.9815 - val_loss: 1.8906 - val_accuracy: 0.8959\n",
      "Epoch 584/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0621 - accuracy: 0.9821 - val_loss: 1.9886 - val_accuracy: 0.8965\n",
      "Epoch 585/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0646 - accuracy: 0.9814 - val_loss: 1.8037 - val_accuracy: 0.8992\n",
      "Epoch 586/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0600 - accuracy: 0.9825 - val_loss: 1.7519 - val_accuracy: 0.8996\n",
      "Epoch 587/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0626 - accuracy: 0.9822 - val_loss: 1.8466 - val_accuracy: 0.8968\n",
      "Epoch 588/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0684 - accuracy: 0.9815 - val_loss: 2.0460 - val_accuracy: 0.8987\n",
      "Epoch 589/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0620 - accuracy: 0.9829 - val_loss: 2.2737 - val_accuracy: 0.9005\n",
      "Epoch 590/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0808 - accuracy: 0.9804 - val_loss: 2.4381 - val_accuracy: 0.9002\n",
      "Epoch 591/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0505 - accuracy: 0.9847 - val_loss: 2.1422 - val_accuracy: 0.8999\n",
      "Epoch 592/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0568 - accuracy: 0.9835 - val_loss: 1.7497 - val_accuracy: 0.8963\n",
      "Epoch 593/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0699 - accuracy: 0.9810 - val_loss: 1.8011 - val_accuracy: 0.8982\n",
      "Epoch 594/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0651 - accuracy: 0.9825 - val_loss: 1.9652 - val_accuracy: 0.8998\n",
      "Epoch 595/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0663 - accuracy: 0.9820 - val_loss: 1.8064 - val_accuracy: 0.8979\n",
      "Epoch 596/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0670 - accuracy: 0.9823 - val_loss: 2.0416 - val_accuracy: 0.9005\n",
      "Epoch 597/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0581 - accuracy: 0.9841 - val_loss: 1.9712 - val_accuracy: 0.8984\n",
      "Epoch 598/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0542 - accuracy: 0.9833 - val_loss: 2.1414 - val_accuracy: 0.8947\n",
      "Epoch 599/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0522 - accuracy: 0.9841 - val_loss: 1.9624 - val_accuracy: 0.8972\n",
      "Epoch 600/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0630 - accuracy: 0.9820 - val_loss: 1.9370 - val_accuracy: 0.9002\n",
      "Epoch 601/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0600 - accuracy: 0.9832 - val_loss: 2.0006 - val_accuracy: 0.8911\n",
      "Epoch 602/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0599 - accuracy: 0.9823 - val_loss: 1.9517 - val_accuracy: 0.8977\n",
      "Epoch 603/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0609 - accuracy: 0.9821 - val_loss: 2.1557 - val_accuracy: 0.8954\n",
      "Epoch 604/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0623 - accuracy: 0.9815 - val_loss: 2.0255 - val_accuracy: 0.8947\n",
      "Epoch 605/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0614 - accuracy: 0.9817 - val_loss: 2.2199 - val_accuracy: 0.9006\n",
      "Epoch 606/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0602 - accuracy: 0.9827 - val_loss: 2.4054 - val_accuracy: 0.8955\n",
      "Epoch 607/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0774 - accuracy: 0.9805 - val_loss: 1.9335 - val_accuracy: 0.8977\n",
      "Epoch 608/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0524 - accuracy: 0.9844 - val_loss: 2.0707 - val_accuracy: 0.8987\n",
      "Epoch 609/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0588 - accuracy: 0.9836 - val_loss: 2.1835 - val_accuracy: 0.8974\n",
      "Epoch 610/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0489 - accuracy: 0.9847 - val_loss: 2.2375 - val_accuracy: 0.9009\n",
      "Epoch 611/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0687 - accuracy: 0.9815 - val_loss: 2.2247 - val_accuracy: 0.8996\n",
      "Epoch 612/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0544 - accuracy: 0.9845 - val_loss: 2.2575 - val_accuracy: 0.8998\n",
      "Epoch 613/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0638 - accuracy: 0.9827 - val_loss: 2.2277 - val_accuracy: 0.8987\n",
      "Epoch 614/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0634 - accuracy: 0.9822 - val_loss: 2.1535 - val_accuracy: 0.8992\n",
      "Epoch 615/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0654 - accuracy: 0.9819 - val_loss: 2.2905 - val_accuracy: 0.8990\n",
      "Epoch 616/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0575 - accuracy: 0.9833 - val_loss: 2.1179 - val_accuracy: 0.9001\n",
      "Epoch 617/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0618 - accuracy: 0.9831 - val_loss: 2.1774 - val_accuracy: 0.8965\n",
      "Epoch 618/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0628 - accuracy: 0.9829 - val_loss: 2.0149 - val_accuracy: 0.8960\n",
      "Epoch 619/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0635 - accuracy: 0.9823 - val_loss: 2.4032 - val_accuracy: 0.8959\n",
      "Epoch 620/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0502 - accuracy: 0.9850 - val_loss: 2.1177 - val_accuracy: 0.8998\n",
      "Epoch 621/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0593 - accuracy: 0.9827 - val_loss: 2.1804 - val_accuracy: 0.9009\n",
      "Epoch 622/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0683 - accuracy: 0.9820 - val_loss: 2.1329 - val_accuracy: 0.8950\n",
      "Epoch 623/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0581 - accuracy: 0.9835 - val_loss: 2.1907 - val_accuracy: 0.8994\n",
      "Epoch 624/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0606 - accuracy: 0.9830 - val_loss: 2.1072 - val_accuracy: 0.8985\n",
      "Epoch 625/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0533 - accuracy: 0.9840 - val_loss: 2.1578 - val_accuracy: 0.8967\n",
      "Epoch 626/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0679 - accuracy: 0.9819 - val_loss: 1.8735 - val_accuracy: 0.8963\n",
      "Epoch 627/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0591 - accuracy: 0.9831 - val_loss: 2.1828 - val_accuracy: 0.9004\n",
      "Epoch 628/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0635 - accuracy: 0.9833 - val_loss: 2.0193 - val_accuracy: 0.8968\n",
      "Epoch 629/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0650 - accuracy: 0.9814 - val_loss: 2.1182 - val_accuracy: 0.8959\n",
      "Epoch 630/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0527 - accuracy: 0.9836 - val_loss: 2.1015 - val_accuracy: 0.8965\n",
      "Epoch 631/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0537 - accuracy: 0.9840 - val_loss: 2.2595 - val_accuracy: 0.8991\n",
      "Epoch 632/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0669 - accuracy: 0.9822 - val_loss: 2.0488 - val_accuracy: 0.8970\n",
      "Epoch 633/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0577 - accuracy: 0.9830 - val_loss: 2.2423 - val_accuracy: 0.8984\n",
      "Epoch 634/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0675 - accuracy: 0.9820 - val_loss: 2.0212 - val_accuracy: 0.8966\n",
      "Epoch 635/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0507 - accuracy: 0.9851 - val_loss: 1.9902 - val_accuracy: 0.8997\n",
      "Epoch 636/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0646 - accuracy: 0.9821 - val_loss: 2.1464 - val_accuracy: 0.8978\n",
      "Epoch 637/1000\n",
      "1500/1500 [==============================] - 14s 10ms/step - loss: 0.0569 - accuracy: 0.9839 - val_loss: 2.4890 - val_accuracy: 0.8988\n",
      "Epoch 638/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0631 - accuracy: 0.9821 - val_loss: 2.4685 - val_accuracy: 0.8957\n",
      "Epoch 639/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0491 - accuracy: 0.9843 - val_loss: 2.4584 - val_accuracy: 0.8956\n",
      "Epoch 640/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0582 - accuracy: 0.9839 - val_loss: 2.2228 - val_accuracy: 0.8943\n",
      "Epoch 641/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0703 - accuracy: 0.9812 - val_loss: 2.0684 - val_accuracy: 0.8977\n",
      "Epoch 642/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0556 - accuracy: 0.9838 - val_loss: 2.3764 - val_accuracy: 0.9005\n",
      "Epoch 643/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0579 - accuracy: 0.9831 - val_loss: 2.2780 - val_accuracy: 0.8988\n",
      "Epoch 644/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0602 - accuracy: 0.9827 - val_loss: 2.2781 - val_accuracy: 0.8978\n",
      "Epoch 645/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0547 - accuracy: 0.9831 - val_loss: 2.1475 - val_accuracy: 0.8963\n",
      "Epoch 646/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0659 - accuracy: 0.9818 - val_loss: 2.1212 - val_accuracy: 0.8982\n",
      "Epoch 647/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0620 - accuracy: 0.9828 - val_loss: 2.0869 - val_accuracy: 0.8949\n",
      "Epoch 648/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0514 - accuracy: 0.9843 - val_loss: 2.1575 - val_accuracy: 0.9001\n",
      "Epoch 649/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0678 - accuracy: 0.9832 - val_loss: 2.2924 - val_accuracy: 0.8972\n",
      "Epoch 650/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0604 - accuracy: 0.9834 - val_loss: 2.1676 - val_accuracy: 0.8979\n",
      "Epoch 651/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0585 - accuracy: 0.9843 - val_loss: 2.1643 - val_accuracy: 0.8981\n",
      "Epoch 652/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0525 - accuracy: 0.9843 - val_loss: 2.0385 - val_accuracy: 0.9011\n",
      "Epoch 653/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0710 - accuracy: 0.9819 - val_loss: 2.2719 - val_accuracy: 0.8961\n",
      "Epoch 654/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0624 - accuracy: 0.9825 - val_loss: 2.3935 - val_accuracy: 0.8961\n",
      "Epoch 655/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0581 - accuracy: 0.9837 - val_loss: 2.2592 - val_accuracy: 0.8987\n",
      "Epoch 656/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0512 - accuracy: 0.9847 - val_loss: 2.1278 - val_accuracy: 0.9006\n",
      "Epoch 657/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0589 - accuracy: 0.9826 - val_loss: 2.4457 - val_accuracy: 0.8918\n",
      "Epoch 658/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0524 - accuracy: 0.9849 - val_loss: 2.4786 - val_accuracy: 0.8997\n",
      "Epoch 659/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0587 - accuracy: 0.9836 - val_loss: 2.1929 - val_accuracy: 0.8957\n",
      "Epoch 660/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0538 - accuracy: 0.9836 - val_loss: 2.4963 - val_accuracy: 0.8957\n",
      "Epoch 661/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0488 - accuracy: 0.9850 - val_loss: 2.4874 - val_accuracy: 0.8980\n",
      "Epoch 662/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0598 - accuracy: 0.9832 - val_loss: 2.1173 - val_accuracy: 0.8976\n",
      "Epoch 663/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0672 - accuracy: 0.9828 - val_loss: 2.1393 - val_accuracy: 0.9012\n",
      "Epoch 664/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0583 - accuracy: 0.9853 - val_loss: 2.1938 - val_accuracy: 0.9010\n",
      "Epoch 665/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0576 - accuracy: 0.9833 - val_loss: 2.2040 - val_accuracy: 0.9028\n",
      "Epoch 666/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0569 - accuracy: 0.9832 - val_loss: 2.2214 - val_accuracy: 0.9016\n",
      "Epoch 667/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0563 - accuracy: 0.9842 - val_loss: 2.3021 - val_accuracy: 0.8942\n",
      "Epoch 668/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0610 - accuracy: 0.9846 - val_loss: 2.4394 - val_accuracy: 0.8989\n",
      "Epoch 669/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0575 - accuracy: 0.9844 - val_loss: 2.3369 - val_accuracy: 0.8989\n",
      "Epoch 670/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0541 - accuracy: 0.9848 - val_loss: 2.2228 - val_accuracy: 0.9000\n",
      "Epoch 671/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0535 - accuracy: 0.9848 - val_loss: 2.1461 - val_accuracy: 0.8954\n",
      "Epoch 672/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0700 - accuracy: 0.9822 - val_loss: 2.2074 - val_accuracy: 0.8982\n",
      "Epoch 673/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0528 - accuracy: 0.9849 - val_loss: 2.5830 - val_accuracy: 0.8991\n",
      "Epoch 674/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0528 - accuracy: 0.9862 - val_loss: 2.4917 - val_accuracy: 0.8984\n",
      "Epoch 675/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0583 - accuracy: 0.9829 - val_loss: 2.3041 - val_accuracy: 0.8999\n",
      "Epoch 676/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0570 - accuracy: 0.9842 - val_loss: 2.3787 - val_accuracy: 0.9003\n",
      "Epoch 677/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0559 - accuracy: 0.9845 - val_loss: 2.5131 - val_accuracy: 0.8978\n",
      "Epoch 678/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0605 - accuracy: 0.9831 - val_loss: 2.5591 - val_accuracy: 0.8992\n",
      "Epoch 679/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0503 - accuracy: 0.9851 - val_loss: 2.7149 - val_accuracy: 0.8987\n",
      "Epoch 680/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0702 - accuracy: 0.9815 - val_loss: 2.2209 - val_accuracy: 0.8988\n",
      "Epoch 681/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0566 - accuracy: 0.9843 - val_loss: 2.5823 - val_accuracy: 0.8988\n",
      "Epoch 682/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0621 - accuracy: 0.9841 - val_loss: 2.0725 - val_accuracy: 0.8928\n",
      "Epoch 683/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0633 - accuracy: 0.9831 - val_loss: 2.3604 - val_accuracy: 0.9000\n",
      "Epoch 684/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0655 - accuracy: 0.9838 - val_loss: 2.7008 - val_accuracy: 0.8980\n",
      "Epoch 685/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0662 - accuracy: 0.9841 - val_loss: 2.4893 - val_accuracy: 0.8986\n",
      "Epoch 686/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0502 - accuracy: 0.9850 - val_loss: 2.3885 - val_accuracy: 0.8992\n",
      "Epoch 687/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0504 - accuracy: 0.9850 - val_loss: 2.4473 - val_accuracy: 0.9004\n",
      "Epoch 688/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0579 - accuracy: 0.9836 - val_loss: 2.5133 - val_accuracy: 0.9003\n",
      "Epoch 689/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0511 - accuracy: 0.9854 - val_loss: 2.4365 - val_accuracy: 0.8986\n",
      "Epoch 690/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0581 - accuracy: 0.9830 - val_loss: 2.3841 - val_accuracy: 0.8990\n",
      "Epoch 691/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0568 - accuracy: 0.9837 - val_loss: 2.5534 - val_accuracy: 0.9003\n",
      "Epoch 692/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0536 - accuracy: 0.9850 - val_loss: 2.7438 - val_accuracy: 0.8981\n",
      "Epoch 693/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0639 - accuracy: 0.9827 - val_loss: 2.3883 - val_accuracy: 0.8958\n",
      "Epoch 694/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0518 - accuracy: 0.9855 - val_loss: 2.6171 - val_accuracy: 0.8983\n",
      "Epoch 695/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0705 - accuracy: 0.9830 - val_loss: 2.6035 - val_accuracy: 0.8992\n",
      "Epoch 696/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0513 - accuracy: 0.9857 - val_loss: 2.5194 - val_accuracy: 0.8988\n",
      "Epoch 697/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0546 - accuracy: 0.9847 - val_loss: 2.2894 - val_accuracy: 0.8945\n",
      "Epoch 698/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0569 - accuracy: 0.9842 - val_loss: 2.3199 - val_accuracy: 0.8963\n",
      "Epoch 699/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0708 - accuracy: 0.9820 - val_loss: 2.3388 - val_accuracy: 0.8978\n",
      "Epoch 700/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0573 - accuracy: 0.9833 - val_loss: 2.3611 - val_accuracy: 0.8939\n",
      "Epoch 701/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0697 - accuracy: 0.9819 - val_loss: 2.1737 - val_accuracy: 0.8969\n",
      "Epoch 702/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0518 - accuracy: 0.9856 - val_loss: 2.5851 - val_accuracy: 0.8988\n",
      "Epoch 703/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0629 - accuracy: 0.9836 - val_loss: 2.3662 - val_accuracy: 0.8977\n",
      "Epoch 704/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0577 - accuracy: 0.9840 - val_loss: 2.3806 - val_accuracy: 0.9014\n",
      "Epoch 705/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0647 - accuracy: 0.9829 - val_loss: 2.3566 - val_accuracy: 0.8991\n",
      "Epoch 706/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0792 - accuracy: 0.9841 - val_loss: 2.2893 - val_accuracy: 0.8957\n",
      "Epoch 707/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0482 - accuracy: 0.9864 - val_loss: 2.4203 - val_accuracy: 0.8987\n",
      "Epoch 708/1000\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0670 - accuracy: 0.9825 - val_loss: 2.3548 - val_accuracy: 0.8975\n",
      "Epoch 709/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0540 - accuracy: 0.9858 - val_loss: 2.5342 - val_accuracy: 0.8993\n",
      "Epoch 710/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0562 - accuracy: 0.9839 - val_loss: 2.3509 - val_accuracy: 0.8989\n",
      "Epoch 711/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0525 - accuracy: 0.9847 - val_loss: 2.2829 - val_accuracy: 0.8955\n",
      "Epoch 712/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0592 - accuracy: 0.9834 - val_loss: 2.3393 - val_accuracy: 0.8971\n",
      "Epoch 713/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0501 - accuracy: 0.9849 - val_loss: 2.2905 - val_accuracy: 0.9014\n",
      "Epoch 714/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0580 - accuracy: 0.9844 - val_loss: 2.3709 - val_accuracy: 0.9003\n",
      "Epoch 715/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0601 - accuracy: 0.9843 - val_loss: 2.2529 - val_accuracy: 0.8970\n",
      "Epoch 716/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0660 - accuracy: 0.9834 - val_loss: 2.1490 - val_accuracy: 0.8987\n",
      "Epoch 717/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0588 - accuracy: 0.9843 - val_loss: 2.4665 - val_accuracy: 0.8970\n",
      "Epoch 718/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0579 - accuracy: 0.9833 - val_loss: 2.3724 - val_accuracy: 0.8977\n",
      "Epoch 719/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0656 - accuracy: 0.9825 - val_loss: 2.5409 - val_accuracy: 0.8937\n",
      "Epoch 720/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0641 - accuracy: 0.9829 - val_loss: 2.5953 - val_accuracy: 0.8972\n",
      "Epoch 721/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0635 - accuracy: 0.9834 - val_loss: 2.3439 - val_accuracy: 0.8986\n",
      "Epoch 722/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0630 - accuracy: 0.9825 - val_loss: 2.3750 - val_accuracy: 0.8965\n",
      "Epoch 723/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0680 - accuracy: 0.9811 - val_loss: 2.4794 - val_accuracy: 0.8948\n",
      "Epoch 724/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0599 - accuracy: 0.9838 - val_loss: 2.5541 - val_accuracy: 0.8986\n",
      "Epoch 725/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0745 - accuracy: 0.9833 - val_loss: 2.6456 - val_accuracy: 0.8984\n",
      "Epoch 726/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0599 - accuracy: 0.9844 - val_loss: 2.6673 - val_accuracy: 0.8982\n",
      "Epoch 727/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0563 - accuracy: 0.9843 - val_loss: 2.5751 - val_accuracy: 0.8967\n",
      "Epoch 728/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0559 - accuracy: 0.9848 - val_loss: 2.4762 - val_accuracy: 0.8973\n",
      "Epoch 729/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0569 - accuracy: 0.9847 - val_loss: 2.6129 - val_accuracy: 0.8989\n",
      "Epoch 730/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0562 - accuracy: 0.9850 - val_loss: 2.4329 - val_accuracy: 0.8980\n",
      "Epoch 731/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0627 - accuracy: 0.9829 - val_loss: 2.3920 - val_accuracy: 0.8989\n",
      "Epoch 732/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0622 - accuracy: 0.9835 - val_loss: 2.3053 - val_accuracy: 0.8982\n",
      "Epoch 733/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0615 - accuracy: 0.9831 - val_loss: 2.5223 - val_accuracy: 0.8980\n",
      "Epoch 734/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0591 - accuracy: 0.9843 - val_loss: 2.4090 - val_accuracy: 0.8967\n",
      "Epoch 735/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0506 - accuracy: 0.9856 - val_loss: 2.3556 - val_accuracy: 0.8980\n",
      "Epoch 736/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0565 - accuracy: 0.9837 - val_loss: 2.5355 - val_accuracy: 0.9011\n",
      "Epoch 737/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0626 - accuracy: 0.9837 - val_loss: 2.4753 - val_accuracy: 0.9000\n",
      "Epoch 738/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0580 - accuracy: 0.9844 - val_loss: 2.6344 - val_accuracy: 0.8982\n",
      "Epoch 739/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0534 - accuracy: 0.9849 - val_loss: 2.4758 - val_accuracy: 0.8972\n",
      "Epoch 740/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0518 - accuracy: 0.9855 - val_loss: 2.9135 - val_accuracy: 0.8962\n",
      "Epoch 741/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0573 - accuracy: 0.9846 - val_loss: 2.6774 - val_accuracy: 0.8960\n",
      "Epoch 742/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0567 - accuracy: 0.9851 - val_loss: 2.6672 - val_accuracy: 0.8957\n",
      "Epoch 743/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0524 - accuracy: 0.9847 - val_loss: 2.3663 - val_accuracy: 0.8960\n",
      "Epoch 744/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0595 - accuracy: 0.9847 - val_loss: 2.3404 - val_accuracy: 0.8979\n",
      "Epoch 745/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0573 - accuracy: 0.9843 - val_loss: 2.4164 - val_accuracy: 0.8995\n",
      "Epoch 746/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0643 - accuracy: 0.9834 - val_loss: 2.3005 - val_accuracy: 0.8957\n",
      "Epoch 747/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0544 - accuracy: 0.9847 - val_loss: 2.8402 - val_accuracy: 0.8957\n",
      "Epoch 748/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0571 - accuracy: 0.9836 - val_loss: 2.6346 - val_accuracy: 0.8995\n",
      "Epoch 749/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0480 - accuracy: 0.9862 - val_loss: 2.7378 - val_accuracy: 0.8978\n",
      "Epoch 750/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0582 - accuracy: 0.9846 - val_loss: 2.5174 - val_accuracy: 0.8969\n",
      "Epoch 751/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0594 - accuracy: 0.9840 - val_loss: 2.8443 - val_accuracy: 0.8998\n",
      "Epoch 752/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0562 - accuracy: 0.9838 - val_loss: 2.8879 - val_accuracy: 0.8947\n",
      "Epoch 753/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0651 - accuracy: 0.9825 - val_loss: 2.8301 - val_accuracy: 0.8987\n",
      "Epoch 754/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0453 - accuracy: 0.9870 - val_loss: 2.8676 - val_accuracy: 0.8977\n",
      "Epoch 755/1000\n",
      "1500/1500 [==============================] - 14s 10ms/step - loss: 0.0587 - accuracy: 0.9840 - val_loss: 2.8172 - val_accuracy: 0.9005\n",
      "Epoch 756/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0649 - accuracy: 0.9834 - val_loss: 2.5655 - val_accuracy: 0.8982\n",
      "Epoch 757/1000\n",
      "1500/1500 [==============================] - 14s 10ms/step - loss: 0.0673 - accuracy: 0.9847 - val_loss: 2.5546 - val_accuracy: 0.9003\n",
      "Epoch 758/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0603 - accuracy: 0.9847 - val_loss: 2.2819 - val_accuracy: 0.9007\n",
      "Epoch 759/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0675 - accuracy: 0.9845 - val_loss: 2.6133 - val_accuracy: 0.8992\n",
      "Epoch 760/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0635 - accuracy: 0.9841 - val_loss: 2.6774 - val_accuracy: 0.8983\n",
      "Epoch 761/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0525 - accuracy: 0.9860 - val_loss: 2.9855 - val_accuracy: 0.8988\n",
      "Epoch 762/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0550 - accuracy: 0.9843 - val_loss: 2.6094 - val_accuracy: 0.8999\n",
      "Epoch 763/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0512 - accuracy: 0.9847 - val_loss: 2.4471 - val_accuracy: 0.8992\n",
      "Epoch 764/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0527 - accuracy: 0.9856 - val_loss: 2.4505 - val_accuracy: 0.8985\n",
      "Epoch 765/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0637 - accuracy: 0.9827 - val_loss: 2.6663 - val_accuracy: 0.8974\n",
      "Epoch 766/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0546 - accuracy: 0.9856 - val_loss: 2.5500 - val_accuracy: 0.8965\n",
      "Epoch 767/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0626 - accuracy: 0.9834 - val_loss: 2.6508 - val_accuracy: 0.8960\n",
      "Epoch 768/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0558 - accuracy: 0.9846 - val_loss: 2.6192 - val_accuracy: 0.9002\n",
      "Epoch 769/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0553 - accuracy: 0.9859 - val_loss: 2.4926 - val_accuracy: 0.8997\n",
      "Epoch 770/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0701 - accuracy: 0.9834 - val_loss: 2.4508 - val_accuracy: 0.8995\n",
      "Epoch 771/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0679 - accuracy: 0.9835 - val_loss: 2.4808 - val_accuracy: 0.8953\n",
      "Epoch 772/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0571 - accuracy: 0.9851 - val_loss: 2.1856 - val_accuracy: 0.8986\n",
      "Epoch 773/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0518 - accuracy: 0.9852 - val_loss: 2.5502 - val_accuracy: 0.8943\n",
      "Epoch 774/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0669 - accuracy: 0.9838 - val_loss: 2.7162 - val_accuracy: 0.8950\n",
      "Epoch 775/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0662 - accuracy: 0.9840 - val_loss: 2.4582 - val_accuracy: 0.8992\n",
      "Epoch 776/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0729 - accuracy: 0.9816 - val_loss: 2.4963 - val_accuracy: 0.8996\n",
      "Epoch 777/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0474 - accuracy: 0.9862 - val_loss: 2.9566 - val_accuracy: 0.8962\n",
      "Epoch 778/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0584 - accuracy: 0.9849 - val_loss: 2.4430 - val_accuracy: 0.8996\n",
      "Epoch 779/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0621 - accuracy: 0.9835 - val_loss: 2.2645 - val_accuracy: 0.8986\n",
      "Epoch 780/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0534 - accuracy: 0.9861 - val_loss: 2.6501 - val_accuracy: 0.8996\n",
      "Epoch 781/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0496 - accuracy: 0.9858 - val_loss: 2.6606 - val_accuracy: 0.8997\n",
      "Epoch 782/1000\n",
      "1500/1500 [==============================] - 14s 10ms/step - loss: 0.0539 - accuracy: 0.9845 - val_loss: 2.6476 - val_accuracy: 0.8982\n",
      "Epoch 783/1000\n",
      "1500/1500 [==============================] - 14s 10ms/step - loss: 0.0627 - accuracy: 0.9842 - val_loss: 2.5956 - val_accuracy: 0.8978\n",
      "Epoch 784/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0606 - accuracy: 0.9836 - val_loss: 2.4294 - val_accuracy: 0.8978\n",
      "Epoch 785/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0687 - accuracy: 0.9846 - val_loss: 2.3560 - val_accuracy: 0.8977\n",
      "Epoch 786/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0451 - accuracy: 0.9874 - val_loss: 2.8918 - val_accuracy: 0.8954\n",
      "Epoch 787/1000\n",
      "1500/1500 [==============================] - 14s 10ms/step - loss: 0.0571 - accuracy: 0.9855 - val_loss: 2.5252 - val_accuracy: 0.8972\n",
      "Epoch 788/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0547 - accuracy: 0.9846 - val_loss: 2.6429 - val_accuracy: 0.9006\n",
      "Epoch 789/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0569 - accuracy: 0.9848 - val_loss: 2.6619 - val_accuracy: 0.8925\n",
      "Epoch 790/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0568 - accuracy: 0.9845 - val_loss: 2.6815 - val_accuracy: 0.9007\n",
      "Epoch 791/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0539 - accuracy: 0.9847 - val_loss: 2.4558 - val_accuracy: 0.8966\n",
      "Epoch 792/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0725 - accuracy: 0.9839 - val_loss: 2.4785 - val_accuracy: 0.8968\n",
      "Epoch 793/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0587 - accuracy: 0.9846 - val_loss: 2.4436 - val_accuracy: 0.9012\n",
      "Epoch 794/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0594 - accuracy: 0.9848 - val_loss: 2.7010 - val_accuracy: 0.8991\n",
      "Epoch 795/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0683 - accuracy: 0.9835 - val_loss: 2.2711 - val_accuracy: 0.8953\n",
      "Epoch 796/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0578 - accuracy: 0.9855 - val_loss: 3.0037 - val_accuracy: 0.8962\n",
      "Epoch 797/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0466 - accuracy: 0.9865 - val_loss: 2.6463 - val_accuracy: 0.8963\n",
      "Epoch 798/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0488 - accuracy: 0.9857 - val_loss: 2.7405 - val_accuracy: 0.8992\n",
      "Epoch 799/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0577 - accuracy: 0.9852 - val_loss: 2.7467 - val_accuracy: 0.8984\n",
      "Epoch 800/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0593 - accuracy: 0.9839 - val_loss: 2.7175 - val_accuracy: 0.8974\n",
      "Epoch 801/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0592 - accuracy: 0.9836 - val_loss: 2.5305 - val_accuracy: 0.8975\n",
      "Epoch 802/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0667 - accuracy: 0.9836 - val_loss: 2.7878 - val_accuracy: 0.8982\n",
      "Epoch 803/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0760 - accuracy: 0.9843 - val_loss: 2.9296 - val_accuracy: 0.8996\n",
      "Epoch 804/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0582 - accuracy: 0.9857 - val_loss: 2.6903 - val_accuracy: 0.8960\n",
      "Epoch 805/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0646 - accuracy: 0.9842 - val_loss: 2.5613 - val_accuracy: 0.8968\n",
      "Epoch 806/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0524 - accuracy: 0.9852 - val_loss: 2.6736 - val_accuracy: 0.8918\n",
      "Epoch 807/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0643 - accuracy: 0.9835 - val_loss: 2.5660 - val_accuracy: 0.8966\n",
      "Epoch 808/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0935 - accuracy: 0.9834 - val_loss: 2.5734 - val_accuracy: 0.9000\n",
      "Epoch 809/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0492 - accuracy: 0.9865 - val_loss: 2.5078 - val_accuracy: 0.8982\n",
      "Epoch 810/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0572 - accuracy: 0.9846 - val_loss: 2.6786 - val_accuracy: 0.8961\n",
      "Epoch 811/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0541 - accuracy: 0.9853 - val_loss: 2.8946 - val_accuracy: 0.8985\n",
      "Epoch 812/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0576 - accuracy: 0.9858 - val_loss: 2.7629 - val_accuracy: 0.8977\n",
      "Epoch 813/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0579 - accuracy: 0.9846 - val_loss: 2.6503 - val_accuracy: 0.8970\n",
      "Epoch 814/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0558 - accuracy: 0.9845 - val_loss: 2.8455 - val_accuracy: 0.8975\n",
      "Epoch 815/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0454 - accuracy: 0.9870 - val_loss: 2.9450 - val_accuracy: 0.8967\n",
      "Epoch 816/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0606 - accuracy: 0.9840 - val_loss: 2.6555 - val_accuracy: 0.8972\n",
      "Epoch 817/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0515 - accuracy: 0.9862 - val_loss: 2.5166 - val_accuracy: 0.8985\n",
      "Epoch 818/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0520 - accuracy: 0.9861 - val_loss: 2.5609 - val_accuracy: 0.8994\n",
      "Epoch 819/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0590 - accuracy: 0.9843 - val_loss: 2.4684 - val_accuracy: 0.8990\n",
      "Epoch 820/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0519 - accuracy: 0.9864 - val_loss: 3.1123 - val_accuracy: 0.8960\n",
      "Epoch 821/1000\n",
      "1500/1500 [==============================] - 14s 10ms/step - loss: 0.0663 - accuracy: 0.9845 - val_loss: 2.7019 - val_accuracy: 0.9005\n",
      "Epoch 822/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0595 - accuracy: 0.9844 - val_loss: 2.4645 - val_accuracy: 0.8963\n",
      "Epoch 823/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0553 - accuracy: 0.9853 - val_loss: 2.6343 - val_accuracy: 0.8967\n",
      "Epoch 824/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0502 - accuracy: 0.9863 - val_loss: 2.8354 - val_accuracy: 0.8992\n",
      "Epoch 825/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0479 - accuracy: 0.9872 - val_loss: 2.8169 - val_accuracy: 0.8961\n",
      "Epoch 826/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0443 - accuracy: 0.9866 - val_loss: 2.6504 - val_accuracy: 0.8964\n",
      "Epoch 827/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0608 - accuracy: 0.9843 - val_loss: 2.4101 - val_accuracy: 0.8978\n",
      "Epoch 828/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0678 - accuracy: 0.9827 - val_loss: 2.5699 - val_accuracy: 0.8979\n",
      "Epoch 829/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0424 - accuracy: 0.9882 - val_loss: 2.5586 - val_accuracy: 0.8971\n",
      "Epoch 830/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0638 - accuracy: 0.9835 - val_loss: 2.4590 - val_accuracy: 0.8989\n",
      "Epoch 831/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0554 - accuracy: 0.9859 - val_loss: 2.6542 - val_accuracy: 0.8982\n",
      "Epoch 832/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0570 - accuracy: 0.9853 - val_loss: 2.7741 - val_accuracy: 0.8992\n",
      "Epoch 833/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0472 - accuracy: 0.9870 - val_loss: 2.8874 - val_accuracy: 0.8994\n",
      "Epoch 834/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0535 - accuracy: 0.9854 - val_loss: 2.7814 - val_accuracy: 0.8991\n",
      "Epoch 835/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0459 - accuracy: 0.9874 - val_loss: 2.8888 - val_accuracy: 0.8937\n",
      "Epoch 836/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0549 - accuracy: 0.9859 - val_loss: 2.4702 - val_accuracy: 0.8998\n",
      "Epoch 837/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0511 - accuracy: 0.9859 - val_loss: 3.0666 - val_accuracy: 0.8978\n",
      "Epoch 838/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0499 - accuracy: 0.9866 - val_loss: 2.8135 - val_accuracy: 0.8904\n",
      "Epoch 839/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0660 - accuracy: 0.9842 - val_loss: 2.6923 - val_accuracy: 0.8976\n",
      "Epoch 840/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0580 - accuracy: 0.9858 - val_loss: 2.7702 - val_accuracy: 0.8958\n",
      "Epoch 841/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0639 - accuracy: 0.9842 - val_loss: 2.6368 - val_accuracy: 0.8975\n",
      "Epoch 842/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0506 - accuracy: 0.9868 - val_loss: 2.8107 - val_accuracy: 0.8998\n",
      "Epoch 843/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0459 - accuracy: 0.9871 - val_loss: 2.9766 - val_accuracy: 0.9010\n",
      "Epoch 844/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0516 - accuracy: 0.9858 - val_loss: 2.6227 - val_accuracy: 0.8977\n",
      "Epoch 845/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0604 - accuracy: 0.9853 - val_loss: 2.9009 - val_accuracy: 0.8994\n",
      "Epoch 846/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0490 - accuracy: 0.9868 - val_loss: 2.8807 - val_accuracy: 0.8993\n",
      "Epoch 847/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0477 - accuracy: 0.9868 - val_loss: 2.6828 - val_accuracy: 0.8949\n",
      "Epoch 848/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0522 - accuracy: 0.9847 - val_loss: 2.6488 - val_accuracy: 0.8987\n",
      "Epoch 849/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0578 - accuracy: 0.9853 - val_loss: 2.8652 - val_accuracy: 0.8963\n",
      "Epoch 850/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0546 - accuracy: 0.9860 - val_loss: 2.8043 - val_accuracy: 0.8924\n",
      "Epoch 851/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0586 - accuracy: 0.9841 - val_loss: 3.1120 - val_accuracy: 0.8977\n",
      "Epoch 852/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0555 - accuracy: 0.9858 - val_loss: 3.0468 - val_accuracy: 0.8977\n",
      "Epoch 853/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0475 - accuracy: 0.9856 - val_loss: 3.1392 - val_accuracy: 0.8981\n",
      "Epoch 854/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0585 - accuracy: 0.9839 - val_loss: 2.9945 - val_accuracy: 0.8967\n",
      "Epoch 855/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0516 - accuracy: 0.9856 - val_loss: 2.6519 - val_accuracy: 0.9020\n",
      "Epoch 856/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0489 - accuracy: 0.9863 - val_loss: 2.4904 - val_accuracy: 0.8973\n",
      "Epoch 857/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0560 - accuracy: 0.9849 - val_loss: 2.5918 - val_accuracy: 0.8981\n",
      "Epoch 858/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0655 - accuracy: 0.9839 - val_loss: 2.9209 - val_accuracy: 0.8974\n",
      "Epoch 859/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0639 - accuracy: 0.9849 - val_loss: 3.0170 - val_accuracy: 0.8976\n",
      "Epoch 860/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0518 - accuracy: 0.9861 - val_loss: 2.7359 - val_accuracy: 0.8961\n",
      "Epoch 861/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0501 - accuracy: 0.9856 - val_loss: 2.9040 - val_accuracy: 0.8984\n",
      "Epoch 862/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0619 - accuracy: 0.9851 - val_loss: 2.8010 - val_accuracy: 0.8960\n",
      "Epoch 863/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0465 - accuracy: 0.9873 - val_loss: 2.9249 - val_accuracy: 0.8981\n",
      "Epoch 864/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0515 - accuracy: 0.9868 - val_loss: 2.9893 - val_accuracy: 0.8983\n",
      "Epoch 865/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0666 - accuracy: 0.9841 - val_loss: 2.7250 - val_accuracy: 0.8996\n",
      "Epoch 866/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0484 - accuracy: 0.9869 - val_loss: 3.0701 - val_accuracy: 0.8994\n",
      "Epoch 867/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0580 - accuracy: 0.9858 - val_loss: 3.0672 - val_accuracy: 0.8983\n",
      "Epoch 868/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0450 - accuracy: 0.9868 - val_loss: 2.8525 - val_accuracy: 0.8976\n",
      "Epoch 869/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0508 - accuracy: 0.9859 - val_loss: 2.8696 - val_accuracy: 0.8991\n",
      "Epoch 870/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0569 - accuracy: 0.9855 - val_loss: 2.7607 - val_accuracy: 0.8980\n",
      "Epoch 871/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0633 - accuracy: 0.9846 - val_loss: 2.8842 - val_accuracy: 0.9008\n",
      "Epoch 872/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0492 - accuracy: 0.9869 - val_loss: 2.8647 - val_accuracy: 0.8988\n",
      "Epoch 873/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0512 - accuracy: 0.9870 - val_loss: 3.0818 - val_accuracy: 0.9010\n",
      "Epoch 874/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0577 - accuracy: 0.9862 - val_loss: 2.7990 - val_accuracy: 0.8989\n",
      "Epoch 875/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0569 - accuracy: 0.9855 - val_loss: 2.8827 - val_accuracy: 0.8995\n",
      "Epoch 876/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0417 - accuracy: 0.9877 - val_loss: 3.1650 - val_accuracy: 0.8971\n",
      "Epoch 877/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0476 - accuracy: 0.9868 - val_loss: 2.9160 - val_accuracy: 0.9002\n",
      "Epoch 878/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0566 - accuracy: 0.9847 - val_loss: 2.7972 - val_accuracy: 0.8979\n",
      "Epoch 879/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0528 - accuracy: 0.9854 - val_loss: 2.7846 - val_accuracy: 0.9010\n",
      "Epoch 880/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0463 - accuracy: 0.9869 - val_loss: 2.6488 - val_accuracy: 0.8988\n",
      "Epoch 881/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0598 - accuracy: 0.9844 - val_loss: 2.6778 - val_accuracy: 0.8987\n",
      "Epoch 882/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0534 - accuracy: 0.9864 - val_loss: 2.9964 - val_accuracy: 0.8953\n",
      "Epoch 883/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0582 - accuracy: 0.9860 - val_loss: 2.8920 - val_accuracy: 0.8989\n",
      "Epoch 884/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0454 - accuracy: 0.9869 - val_loss: 2.9693 - val_accuracy: 0.8979\n",
      "Epoch 885/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0596 - accuracy: 0.9849 - val_loss: 3.0051 - val_accuracy: 0.8958\n",
      "Epoch 886/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0588 - accuracy: 0.9857 - val_loss: 2.9114 - val_accuracy: 0.8959\n",
      "Epoch 887/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0507 - accuracy: 0.9863 - val_loss: 2.6896 - val_accuracy: 0.8992\n",
      "Epoch 888/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0477 - accuracy: 0.9861 - val_loss: 2.9218 - val_accuracy: 0.8992\n",
      "Epoch 889/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0564 - accuracy: 0.9855 - val_loss: 2.7289 - val_accuracy: 0.8959\n",
      "Epoch 890/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0506 - accuracy: 0.9856 - val_loss: 2.8051 - val_accuracy: 0.8981\n",
      "Epoch 891/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0448 - accuracy: 0.9873 - val_loss: 3.0834 - val_accuracy: 0.8979\n",
      "Epoch 892/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0621 - accuracy: 0.9841 - val_loss: 2.6859 - val_accuracy: 0.8972\n",
      "Epoch 893/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0508 - accuracy: 0.9866 - val_loss: 2.9927 - val_accuracy: 0.9003\n",
      "Epoch 894/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0493 - accuracy: 0.9865 - val_loss: 2.8851 - val_accuracy: 0.9002\n",
      "Epoch 895/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0521 - accuracy: 0.9862 - val_loss: 2.8084 - val_accuracy: 0.8982\n",
      "Epoch 896/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0551 - accuracy: 0.9866 - val_loss: 2.9216 - val_accuracy: 0.8972\n",
      "Epoch 897/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0492 - accuracy: 0.9873 - val_loss: 3.1008 - val_accuracy: 0.8978\n",
      "Epoch 898/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0510 - accuracy: 0.9869 - val_loss: 2.5664 - val_accuracy: 0.8970\n",
      "Epoch 899/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0653 - accuracy: 0.9843 - val_loss: 2.7957 - val_accuracy: 0.8973\n",
      "Epoch 900/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0583 - accuracy: 0.9853 - val_loss: 2.7980 - val_accuracy: 0.8985\n",
      "Epoch 901/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0542 - accuracy: 0.9859 - val_loss: 2.7456 - val_accuracy: 0.9005\n",
      "Epoch 902/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0444 - accuracy: 0.9876 - val_loss: 2.8776 - val_accuracy: 0.8989\n",
      "Epoch 903/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0632 - accuracy: 0.9848 - val_loss: 2.7450 - val_accuracy: 0.8985\n",
      "Epoch 904/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0480 - accuracy: 0.9869 - val_loss: 2.9366 - val_accuracy: 0.8996\n",
      "Epoch 905/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0515 - accuracy: 0.9867 - val_loss: 2.5576 - val_accuracy: 0.8980\n",
      "Epoch 906/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0848 - accuracy: 0.9819 - val_loss: 2.6086 - val_accuracy: 0.8999\n",
      "Epoch 907/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0556 - accuracy: 0.9866 - val_loss: 2.8579 - val_accuracy: 0.8987\n",
      "Epoch 908/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0461 - accuracy: 0.9871 - val_loss: 2.5991 - val_accuracy: 0.8998\n",
      "Epoch 909/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0466 - accuracy: 0.9874 - val_loss: 2.7180 - val_accuracy: 0.8979\n",
      "Epoch 910/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0525 - accuracy: 0.9871 - val_loss: 2.8555 - val_accuracy: 0.8992\n",
      "Epoch 911/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0600 - accuracy: 0.9856 - val_loss: 3.0466 - val_accuracy: 0.9018\n",
      "Epoch 912/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0489 - accuracy: 0.9860 - val_loss: 2.8586 - val_accuracy: 0.8976\n",
      "Epoch 913/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0520 - accuracy: 0.9855 - val_loss: 2.8151 - val_accuracy: 0.8967\n",
      "Epoch 914/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0643 - accuracy: 0.9835 - val_loss: 2.6189 - val_accuracy: 0.8963\n",
      "Epoch 915/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0535 - accuracy: 0.9860 - val_loss: 2.9479 - val_accuracy: 0.8988\n",
      "Epoch 916/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0486 - accuracy: 0.9867 - val_loss: 3.0505 - val_accuracy: 0.8957\n",
      "Epoch 917/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0460 - accuracy: 0.9871 - val_loss: 3.1533 - val_accuracy: 0.8946\n",
      "Epoch 918/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0495 - accuracy: 0.9855 - val_loss: 2.9217 - val_accuracy: 0.9002\n",
      "Epoch 919/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0590 - accuracy: 0.9854 - val_loss: 2.8329 - val_accuracy: 0.9007\n",
      "Epoch 920/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0552 - accuracy: 0.9858 - val_loss: 2.8726 - val_accuracy: 0.8965\n",
      "Epoch 921/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0617 - accuracy: 0.9848 - val_loss: 2.5556 - val_accuracy: 0.8981\n",
      "Epoch 922/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0587 - accuracy: 0.9854 - val_loss: 2.9838 - val_accuracy: 0.8985\n",
      "Epoch 923/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0413 - accuracy: 0.9880 - val_loss: 3.3502 - val_accuracy: 0.8985\n",
      "Epoch 924/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0548 - accuracy: 0.9858 - val_loss: 2.8613 - val_accuracy: 0.8988\n",
      "Epoch 925/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0485 - accuracy: 0.9871 - val_loss: 3.1373 - val_accuracy: 0.8963\n",
      "Epoch 926/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0617 - accuracy: 0.9844 - val_loss: 3.3037 - val_accuracy: 0.8977\n",
      "Epoch 927/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0580 - accuracy: 0.9868 - val_loss: 2.9015 - val_accuracy: 0.8975\n",
      "Epoch 928/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0491 - accuracy: 0.9875 - val_loss: 2.4904 - val_accuracy: 0.8961\n",
      "Epoch 929/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0458 - accuracy: 0.9871 - val_loss: 2.8994 - val_accuracy: 0.8961\n",
      "Epoch 930/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0455 - accuracy: 0.9871 - val_loss: 2.9807 - val_accuracy: 0.8982\n",
      "Epoch 931/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0498 - accuracy: 0.9863 - val_loss: 3.0859 - val_accuracy: 0.8928\n",
      "Epoch 932/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0515 - accuracy: 0.9862 - val_loss: 2.9951 - val_accuracy: 0.8978\n",
      "Epoch 933/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0478 - accuracy: 0.9869 - val_loss: 3.2717 - val_accuracy: 0.8982\n",
      "Epoch 934/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0507 - accuracy: 0.9866 - val_loss: 3.4034 - val_accuracy: 0.8958\n",
      "Epoch 935/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0509 - accuracy: 0.9859 - val_loss: 2.8643 - val_accuracy: 0.8953\n",
      "Epoch 936/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0493 - accuracy: 0.9870 - val_loss: 3.2607 - val_accuracy: 0.8992\n",
      "Epoch 937/1000\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0554 - accuracy: 0.9855 - val_loss: 3.3303 - val_accuracy: 0.8937\n",
      "Epoch 938/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0623 - accuracy: 0.9852 - val_loss: 2.8419 - val_accuracy: 0.8957\n",
      "Epoch 939/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0423 - accuracy: 0.9878 - val_loss: 3.2729 - val_accuracy: 0.8985\n",
      "Epoch 940/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0455 - accuracy: 0.9875 - val_loss: 2.9194 - val_accuracy: 0.8996\n",
      "Epoch 941/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0412 - accuracy: 0.9886 - val_loss: 3.4850 - val_accuracy: 0.8971\n",
      "Epoch 942/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0578 - accuracy: 0.9853 - val_loss: 2.8948 - val_accuracy: 0.8962\n",
      "Epoch 943/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0564 - accuracy: 0.9859 - val_loss: 3.3660 - val_accuracy: 0.8985\n",
      "Epoch 944/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0391 - accuracy: 0.9887 - val_loss: 2.9324 - val_accuracy: 0.8999\n",
      "Epoch 945/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0575 - accuracy: 0.9860 - val_loss: 3.1488 - val_accuracy: 0.8957\n",
      "Epoch 946/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0465 - accuracy: 0.9865 - val_loss: 3.2655 - val_accuracy: 0.8986\n",
      "Epoch 947/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0643 - accuracy: 0.9854 - val_loss: 2.7864 - val_accuracy: 0.8960\n",
      "Epoch 948/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0594 - accuracy: 0.9859 - val_loss: 3.0815 - val_accuracy: 0.8951\n",
      "Epoch 949/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0565 - accuracy: 0.9868 - val_loss: 2.9866 - val_accuracy: 0.8952\n",
      "Epoch 950/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0511 - accuracy: 0.9867 - val_loss: 3.0561 - val_accuracy: 0.8978\n",
      "Epoch 951/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0560 - accuracy: 0.9850 - val_loss: 3.2529 - val_accuracy: 0.8999\n",
      "Epoch 952/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0562 - accuracy: 0.9853 - val_loss: 2.9334 - val_accuracy: 0.8971\n",
      "Epoch 953/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0534 - accuracy: 0.9863 - val_loss: 3.0136 - val_accuracy: 0.8954\n",
      "Epoch 954/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0415 - accuracy: 0.9874 - val_loss: 2.9885 - val_accuracy: 0.8977\n",
      "Epoch 955/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0495 - accuracy: 0.9868 - val_loss: 3.1344 - val_accuracy: 0.8998\n",
      "Epoch 956/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0586 - accuracy: 0.9861 - val_loss: 3.1657 - val_accuracy: 0.9006\n",
      "Epoch 957/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0541 - accuracy: 0.9858 - val_loss: 3.0187 - val_accuracy: 0.9000\n",
      "Epoch 958/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0602 - accuracy: 0.9846 - val_loss: 2.8483 - val_accuracy: 0.8963\n",
      "Epoch 959/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0627 - accuracy: 0.9842 - val_loss: 3.2287 - val_accuracy: 0.8956\n",
      "Epoch 960/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0618 - accuracy: 0.9852 - val_loss: 3.3625 - val_accuracy: 0.9003\n",
      "Epoch 961/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0445 - accuracy: 0.9884 - val_loss: 3.1399 - val_accuracy: 0.8966\n",
      "Epoch 962/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0532 - accuracy: 0.9856 - val_loss: 2.8900 - val_accuracy: 0.8966\n",
      "Epoch 963/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0517 - accuracy: 0.9865 - val_loss: 3.1801 - val_accuracy: 0.8970\n",
      "Epoch 964/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0450 - accuracy: 0.9885 - val_loss: 3.7798 - val_accuracy: 0.8980\n",
      "Epoch 965/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0714 - accuracy: 0.9845 - val_loss: 3.3318 - val_accuracy: 0.8963\n",
      "Epoch 966/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0648 - accuracy: 0.9861 - val_loss: 3.0958 - val_accuracy: 0.8979\n",
      "Epoch 967/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0502 - accuracy: 0.9875 - val_loss: 2.9961 - val_accuracy: 0.9001\n",
      "Epoch 968/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0785 - accuracy: 0.9839 - val_loss: 2.5817 - val_accuracy: 0.8945\n",
      "Epoch 969/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0625 - accuracy: 0.9848 - val_loss: 3.1221 - val_accuracy: 0.8998\n",
      "Epoch 970/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0488 - accuracy: 0.9870 - val_loss: 3.1750 - val_accuracy: 0.8970\n",
      "Epoch 971/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0438 - accuracy: 0.9878 - val_loss: 3.3077 - val_accuracy: 0.8992\n",
      "Epoch 972/1000\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0573 - accuracy: 0.9855 - val_loss: 3.2264 - val_accuracy: 0.8983\n",
      "Epoch 973/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0507 - accuracy: 0.9862 - val_loss: 3.3591 - val_accuracy: 0.8971\n",
      "Epoch 974/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0544 - accuracy: 0.9863 - val_loss: 3.2416 - val_accuracy: 0.9003\n",
      "Epoch 975/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0469 - accuracy: 0.9871 - val_loss: 3.1527 - val_accuracy: 0.8976\n",
      "Epoch 976/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0540 - accuracy: 0.9856 - val_loss: 2.8709 - val_accuracy: 0.8977\n",
      "Epoch 977/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0691 - accuracy: 0.9843 - val_loss: 2.9292 - val_accuracy: 0.8976\n",
      "Epoch 978/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0524 - accuracy: 0.9864 - val_loss: 3.0168 - val_accuracy: 0.9003\n",
      "Epoch 979/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0444 - accuracy: 0.9877 - val_loss: 3.0558 - val_accuracy: 0.8954\n",
      "Epoch 980/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0478 - accuracy: 0.9879 - val_loss: 2.7665 - val_accuracy: 0.8969\n",
      "Epoch 981/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0508 - accuracy: 0.9859 - val_loss: 3.0830 - val_accuracy: 0.8988\n",
      "Epoch 982/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0532 - accuracy: 0.9862 - val_loss: 3.1903 - val_accuracy: 0.9007\n",
      "Epoch 983/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0551 - accuracy: 0.9865 - val_loss: 3.3068 - val_accuracy: 0.8980\n",
      "Epoch 984/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0531 - accuracy: 0.9870 - val_loss: 3.2152 - val_accuracy: 0.8992\n",
      "Epoch 985/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0556 - accuracy: 0.9870 - val_loss: 3.1048 - val_accuracy: 0.9012\n",
      "Epoch 986/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0558 - accuracy: 0.9860 - val_loss: 3.3424 - val_accuracy: 0.8995\n",
      "Epoch 987/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0571 - accuracy: 0.9869 - val_loss: 3.5192 - val_accuracy: 0.8976\n",
      "Epoch 988/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0448 - accuracy: 0.9878 - val_loss: 3.2459 - val_accuracy: 0.8995\n",
      "Epoch 989/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0662 - accuracy: 0.9863 - val_loss: 2.6549 - val_accuracy: 0.8982\n",
      "Epoch 990/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0475 - accuracy: 0.9866 - val_loss: 3.0816 - val_accuracy: 0.8996\n",
      "Epoch 991/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0437 - accuracy: 0.9880 - val_loss: 3.1486 - val_accuracy: 0.9006\n",
      "Epoch 992/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0544 - accuracy: 0.9870 - val_loss: 3.2274 - val_accuracy: 0.9013\n",
      "Epoch 993/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0537 - accuracy: 0.9870 - val_loss: 2.9809 - val_accuracy: 0.9005\n",
      "Epoch 994/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0447 - accuracy: 0.9879 - val_loss: 2.9233 - val_accuracy: 0.8981\n",
      "Epoch 995/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0463 - accuracy: 0.9880 - val_loss: 3.0656 - val_accuracy: 0.8996\n",
      "Epoch 996/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0459 - accuracy: 0.9884 - val_loss: 3.3634 - val_accuracy: 0.8957\n",
      "Epoch 997/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0680 - accuracy: 0.9858 - val_loss: 3.1972 - val_accuracy: 0.9008\n",
      "Epoch 998/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0416 - accuracy: 0.9890 - val_loss: 3.5353 - val_accuracy: 0.8978\n",
      "Epoch 999/1000\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0520 - accuracy: 0.9858 - val_loss: 3.0156 - val_accuracy: 0.8982\n",
      "Epoch 1000/1000\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0491 - accuracy: 0.9872 - val_loss: 3.5433 - val_accuracy: 0.8994\n",
      "Execution Time In Seconds =  12799.0\n",
      "Execution Time In Minutes =  213.3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build the Model\n",
    "\n",
    "print(\"This might take a while ... maybe 15+ minutes ...depends on your computer.\")\n",
    "start_time = time.time()\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add( tf.keras.layers.Flatten( input_shape=INPUT_SHAPE ) )\n",
    "model.add( DENSE_LAYER_01 )\n",
    "model.add( DROPOUT_LAYER )\n",
    "model.add( DENSE_LAYER_02 )\n",
    "model.add( DENSE_LAYER_XX )\n",
    "#model.compile( optimizer=theOptimizer, loss=theLossMetric )\n",
    "model.compile( optimizer=theOptimizer, loss=theLossMetric, metrics=['accuracy'] )\n",
    "#model.fit(x_train, y_train, epochs=theEpochs, verbose = verboseFlag )\n",
    "model.fit(x_train, y_train, epochs=theEpochs, validation_split=theSplit, batch_size=theBatchSize, verbose = verboseFlag )\n",
    "\n",
    "\n",
    "Time_In_Seconds = round( time.time()-start_time, 0 )\n",
    "Time_In_Minutes = round( Time_In_Seconds / 60, 1 )\n",
    "print(\"Execution Time In Seconds = \", Time_In_Seconds )\n",
    "print(\"Execution Time In Minutes = \", Time_In_Minutes )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n",
      "WHO =  4057  Predicte = 5  Actual =  5\n",
      "WHO =  6813  Predicte = 7  Actual =  7\n",
      "WHO =  8735  Predicte = 1  Actual =  1\n",
      "WHO =  4628  Predicte = 0  Actual =  0\n",
      "WHO =  5036  Predicte = 3  Actual =  4\n",
      "WHO =  5768  Predicte = 3  Actual =  3\n",
      "WHO =  8  Predicte = 5  Actual =  5\n",
      "WHO =  9103  Predicte = 1  Actual =  1\n",
      "WHO =  9477  Predicte = 4  Actual =  4\n",
      "WHO =  1663  Predicte = 5  Actual =  5\n",
      "WHO =  8583  Predicte = 7  Actual =  7\n",
      "WHO =  1992  Predicte = 1  Actual =  1\n",
      "WHO =  8118  Predicte = 8  Actual =  8\n",
      "WHO =  9098  Predicte = 1  Actual =  1\n",
      "WHO =  1576  Predicte = 2  Actual =  2\n",
      "WHO =  5761  Predicte = 1  Actual =  1\n",
      "WHO =  3164  Predicte = 2  Actual =  2\n",
      "WHO =  2353  Predicte = 8  Actual =  8\n",
      "WHO =  8418  Predicte = 0  Actual =  0\n",
      "WHO =  4974  Predicte = 1  Actual =  1\n",
      "WHO =  7166  Predicte = 9  Actual =  9\n",
      "WHO =  7282  Predicte = 4  Actual =  4\n",
      "WHO =  2937  Predicte = 1  Actual =  1\n",
      "WHO =  4444  Predicte = 3  Actual =  3\n",
      "WHO =  930  Predicte = 0  Actual =  0\n",
      "WHO =  8296  Predicte = 2  Actual =  4\n",
      "WHO =  3998  Predicte = 7  Actual =  7\n",
      "WHO =  849  Predicte = 1  Actual =  1\n",
      "WHO =  4989  Predicte = 8  Actual =  8\n",
      "WHO =  8181  Predicte = 7  Actual =  7\n",
      "WHO =  1377  Predicte = 6  Actual =  4\n",
      "WHO =  9201  Predicte = 9  Actual =  9\n",
      "WHO =  5882  Predicte = 5  Actual =  5\n",
      "WHO =  3351  Predicte = 7  Actual =  7\n",
      "WHO =  9764  Predicte = 0  Actual =  0\n",
      "WHO =  5797  Predicte = 7  Actual =  7\n",
      "WHO =  4203  Predicte = 2  Actual =  2\n",
      "WHO =  6929  Predicte = 0  Actual =  0\n",
      "WHO =  3233  Predicte = 5  Actual =  5\n",
      "WHO =  3932  Predicte = 2  Actual =  2\n",
      "WHO =  5358  Predicte = 4  Actual =  4\n",
      "WHO =  5441  Predicte = 4  Actual =  4\n",
      "WHO =  2418  Predicte = 4  Actual =  4\n",
      "WHO =  5308  Predicte = 1  Actual =  1\n",
      "WHO =  761  Predicte = 6  Actual =  6\n",
      "WHO =  9207  Predicte = 8  Actual =  8\n",
      "WHO =  4431  Predicte = 6  Actual =  6\n",
      "WHO =  2441  Predicte = 4  Actual =  4\n",
      "WHO =  2046  Predicte = 0  Actual =  0\n",
      "WHO =  4595  Predicte = 2  Actual =  6\n",
      "WHO =  5228  Predicte = 6  Actual =  6\n",
      "WHO =  9620  Predicte = 0  Actual =  0\n",
      "WHO =  5963  Predicte = 1  Actual =  1\n",
      "WHO =  2380  Predicte = 1  Actual =  1\n",
      "WHO =  7324  Predicte = 5  Actual =  5\n",
      "WHO =  8608  Predicte = 5  Actual =  5\n",
      "WHO =  7367  Predicte = 5  Actual =  5\n",
      "WHO =  9368  Predicte = 4  Actual =  4\n",
      "WHO =  1526  Predicte = 9  Actual =  9\n",
      "WHO =  7588  Predicte = 3  Actual =  3\n",
      "WHO =  4881  Predicte = 3  Actual =  3\n",
      "WHO =  5662  Predicte = 7  Actual =  7\n",
      "WHO =  5808  Predicte = 0  Actual =  0\n",
      "WHO =  2203  Predicte = 3  Actual =  3\n",
      "WHO =  8920  Predicte = 3  Actual =  4\n",
      "WHO =  1612  Predicte = 3  Actual =  3\n",
      "WHO =  6460  Predicte = 0  Actual =  0\n",
      "WHO =  383  Predicte = 3  Actual =  3\n",
      "WHO =  9020  Predicte = 1  Actual =  1\n",
      "WHO =  2310  Predicte = 8  Actual =  8\n",
      "WHO =  3840  Predicte = 1  Actual =  1\n",
      "WHO =  4833  Predicte = 7  Actual =  7\n",
      "WHO =  8388  Predicte = 3  Actual =  3\n",
      "WHO =  1276  Predicte = 9  Actual =  9\n",
      "WHO =  6476  Predicte = 5  Actual =  5\n",
      "WHO =  3410  Predicte = 7  Actual =  7\n",
      "WHO =  9521  Predicte = 9  Actual =  9\n",
      "WHO =  8974  Predicte = 6  Actual =  6\n",
      "WHO =  9622  Predicte = 3  Actual =  3\n",
      "WHO =  8776  Predicte = 7  Actual =  7\n",
      "WHO =  2336  Predicte = 0  Actual =  0\n",
      "WHO =  4484  Predicte = 3  Actual =  4\n",
      "WHO =  5771  Predicte = 9  Actual =  9\n",
      "WHO =  9239  Predicte = 7  Actual =  7\n",
      "WHO =  8864  Predicte = 3  Actual =  3\n",
      "WHO =  5221  Predicte = 0  Actual =  0\n",
      "WHO =  1664  Predicte = 1  Actual =  1\n",
      "WHO =  2667  Predicte = 5  Actual =  5\n",
      "WHO =  1659  Predicte = 1  Actual =  1\n",
      "WHO =  3174  Predicte = 2  Actual =  6\n",
      "WHO =  4757  Predicte = 3  Actual =  3\n",
      "WHO =  5652  Predicte = 2  Actual =  2\n",
      "WHO =  1437  Predicte = 6  Actual =  6\n",
      "WHO =  7617  Predicte = 5  Actual =  5\n",
      "WHO =  8060  Predicte = 6  Actual =  6\n",
      "WHO =  8516  Predicte = 1  Actual =  1\n",
      "WHO =  5738  Predicte = 9  Actual =  9\n",
      "WHO =  3501  Predicte = 2  Actual =  2\n",
      "WHO =  2121  Predicte = 5  Actual =  5\n",
      "WHO =  5670  Predicte = 1  Actual =  1\n",
      " --------- \n",
      "accuracy =  0.8938\n"
     ]
    }
   ],
   "source": [
    "probs = model.predict( x_test )\n",
    "\n",
    "pred_list = []\n",
    "for p in probs :\n",
    "    pred_list.append( np.argmax( p ) )\n",
    "pred = np.array( pred_list )\n",
    "acc_score = metrics.accuracy_score( y_test, pred)\n",
    "\n",
    "for i in range(100) :\n",
    "    who = getRandomIndex( x_test )\n",
    "    print(\"WHO = \", who, \" Predicte =\", pred[who], \" Actual = \", y_test[who] )\n",
    "\n",
    "print(\" --------- \")\n",
    "print(\"accuracy = \", acc_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 4.1923 - accuracy: 0.8938\n",
      "loss= 4.192263126373291\n",
      "accuracy 0.8938000202178955\n"
     ]
    }
   ],
   "source": [
    "NN_loss, NN_acc = model.evaluate( x_test, y_test )\n",
    "print(\"loss=\",NN_loss)\n",
    "print(\"accuracy\",NN_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: TF_Fashion_Model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: TF_Fashion_Model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save( theTensorFlowSaveFile )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RestoredOptimizer` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RestoredOptimizer`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "new_model= tf.keras.models.load_model( theTensorFlowSaveFile )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = new_model.predict( x_test ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "predict= 8 actual= 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2ed8dba10>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "who=getRandomIndex( x_test )\n",
    "print( predictions[who]) # probability score\n",
    "result = np.argmax( list(predictions[who]) )\n",
    "print(\"predict=\",result,\"actual=\",y_test[who])\n",
    "plt.imshow( x_test[who], plt.cm.binary )\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy of RANDOM FOREST and NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF accuracy 0.9\n",
      "NN accuracy 0.9\n"
     ]
    }
   ],
   "source": [
    "print(\"RF accuracy\", round(RF_acc,1) )\n",
    "print(\"NN accuracy\",round(NN_acc,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook 99_minist_fashion_Kwok.ipynb to pdf\n",
      "[NbConvertApp] Support files will be in 99_minist_fashion_Kwok_files/\n",
      "[NbConvertApp] Making directory ./99_minist_fashion_Kwok_files\n",
      "[NbConvertApp] Writing 198973 bytes to notebook.tex\n",
      "[NbConvertApp] Building PDF\n",
      "[NbConvertApp] Running xelatex 3 times: ['xelatex', 'notebook.tex', '-quiet']\n",
      "[NbConvertApp] Running bibtex 1 time: ['bibtex', 'notebook']\n",
      "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
      "[NbConvertApp] PDF successfully created\n",
      "[NbConvertApp] Writing 121297 bytes to 99_minist_fashion_Kwok.pdf\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to pdf 99_minist_fashion_Kwok.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
